\documentclass[12pt]{article}

\input{../../../../etc/macros}
%\input{../../../../etc/mzlatex_macros}
\input{../../../../etc/pdf_macros}

\bibliographystyle{plain}

\begin{document}

\myheader
\mytitle

\hr

\sectiontitle{}

\hr

\usefirefox

\hr

\visual{Study Tip}{../../../../CommonInformation/Lessons/studytip.png}
\section*{Study Tip}

\hr

\visual{Rating}{../../../../CommonInformation/Lessons/rating.png}
\section*{Rating} %one of 
% Everyone: contains no mathematics.
% Student: contains scenes of mild algebra or calculus that may require guidance.
% Mathematically Mature: may contain mathematics beyond calculus with proofs.
% Mathematicians Only: prolonged scenes of intense rigor.

\hr

\visual{Section Starter Question}{../../../../CommonInformation/Lessons/question_mark.png}
\section*{Section Starter Question}

\hr

\visual{Key Concepts}{../../../../CommonInformation/Lessons/keyconcepts.png}
\section*{Key Concepts}

\begin{enumerate}
  \item Denote the transition probability
of the Markov chain $X_n$ from state $x_i$ to state $x_j$, for \( i, j
= 1, \dots,  r\) , by \( p_{ij} \).  A 
necessary and sufficient condition for the Markov chain $X$ to be lumpable
with respect to the partition $S$ is that for every pair of sets
$E_{\xi}$ and $E_{\eta}$, \( sum_{x_k \in E_{\eta}} p_{ik} \) has the
same value for every \(x_i \in E_{\xi} \). These common values form
the transition probabilities $p_{\xi, \eta}$ for the lumped chain.

  \item 
  \item 
\end{enumerate}

\hr

\visual{Vocabulary}{../../../../CommonInformation/Lessons/vocabulary.png}
\section*{Vocabulary}
\begin{enumerate}
  \item   Let $X_n$ be a Markov chain with state space \( \mathcal{X} =
\set{x_1 x_2, \dots x k} \) and initial distribution \( \xi \). Given a
partition \( \bar{S} = \set{E_1, E_2,  \dots, E_v} \) of the state space
  $S$, a new chain \( \bar{X}_n \) can be defined as
follows: At the $j$th step, the state of the new chain is the set
$E_k$ when $E_k$ contains the state of the $j$th step of the original
chain. Assign the transition probabilities for $\bar{X}_n$ as follows:
The initial distribution is
\[
  \prob{\bar{X}_0 = E_i} = \probsub{X_0 \in E_i}.
\]
Given the initial state, the transition probability for step $1$ is
\[
  \prob{\bar{X}_1 = E_j \given \bar{X}_0 = E_i} = \probsub{\xi}{X_0}
  \in E_i }.
\]
In general for the $n$th step
\[
  \prob{\bar{X}_1 = E_t \given \bar{X}_{n-1} = E_{s_{n-1}},
    \bar{X}_{n-2} = E_{s_{n-2}}, \dots,  \bar{X}_1 = E_{s_1},
    \bar{X}_0 = E_i} = \probsub{\xi}{X_0} \in E_i \given X_{n-1} \in E_{s_{n-1}},
    X_{n-2} \in E_{s_{n-2}}, \dots,  X_1 \in E_{s_1},
    X_0 \in E_i}.
\]
Call this new chain \( \bar{X}_n \), a \defn{lumped
  chain}\index{lumped chain} of the
Markov chain \( X_n \).

  \item 
  A Markov chain with $X_n$ state space with state space $\mathcal{X}$
  is said to be \defn{lumpable}\index{lumpable} with respect to a partition $S$ of
  $\mathcal{X}$ if for every starting distribution \( X_0 \) the lumped chain \(
  \bar{X}_n \) is a Markov chain with state space $S$ and the
  associated transition probabilities do not depend on the choice of
  $X_0$.  
\end{enumerate}

\hr

\visual{Mathematical Ideas}{../../../../CommonInformation/Lessons/mathematicalideas.png}
\section*{Mathematical Ideas}

It is often convenient to partition the states of a chain into
aggregates or lumps and to view the dynamics at a coarser level as the
system of interest moves among the lumps. Examples of such aggregation
include a weather model lumping the states ``drizzle'', ``rain'' and
``snow'' into one state called ``precipitation'' or a physical model
aggregating the microstates of a physical system into so-called coarse
grained ‘‘mesostates’’ each representing many microstates. Although
the dynamics moving between the lumps is not even Markovian in general
[10], there is a natural choice for a Markov chain model on the set of
lumped states. This choice [10—13] matches the time evolution of the
original unlumped chain started at equilibrium. In the present work we
bound the error of the dynamics predicted by this lumped chain
considered as a model of the unlumped chain. Our goal in this letter
is to analyze the accuracy of such coarse grained models as compared
to the exact microscopic behavior, i.e. to bound the error in a
coarse grained description.

\subsection*{Lumpable Markov Chains}

%% https://www.math.pku.edu.cn/teachers/yaoy/Fall2011/Kemeny-Snell_Chapter6.3-4.pdf
%% https://web.nmsu.edu/~jtian/PB/2006-3.pdf
%% https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3207820/
%% http://www.sci.sdsu.edu/~salamon/OLPpublished.pdf

\begin{definition}
  Let $X_n$ be a Markov chain with state space \( \mathcal{X} =
\set{x_1 x_2, \dots x_k} \) and initial distribution \( \xi \). Given a
partition \( \bar{S} = \set{E_1, E_2,  \dots, E_v} \) of the state space
  $S$, a new chain \( \bar{X}_n \) can be defined as
follows: At the $j$th step, the state of the new chain is the set
$E_k$ when $E_k$ contains the state of the $j$th step of the original
chain.  Assign the transition probabilities for $\bar{X}_n$ as follows:
The initial distribution is
\[
  \prob{\bar{X}_0 = E_i} = \probsub{\xi}{X_0 \in E_i}.
\]
Given the initial state, the transition probability for step $1$ is
\[
  \prob{\bar{X}_1 = E_j \given \bar{X}_0 = E_i} = \probsub{\xi}{X_0
  \in E_i }.
\]
In general for the $n$th step
\[
  \prob{\bar{X}_n = E_t \given \bar{X}_{n-1} = E_{t_{n-1}},
    \bar{X}_{n-2} = E_{t_{n-2}}, \dots,  \bar{X}_1 = E_{t_1},
    \bar{X}_0 = E_i} = \probsub{\xi}{X_0} \in E_i \given X_{n-1} \in E_{t_{n-1}},
    X_{n-2} \in E_{t_{n-2}}, \dots,  X_1 \in E_{t_1},
    X_0 \in E_i}.
\]
Call this new chain \( \bar{X}_n \), a \defn{lumped
  chain}\index{lumped chain} of the
Markov chain \( X_n \).
\end{definition}

A lumped chain of a given Markov chain need not be a Markov chain in
general. [Need example]

\begin{definition}
  A Markov chain with $X_n$ state space with state space $\mathcal{X}$
  is said to be \defn{lumpable}\index{lumpable} with respect to a partition $S$ of
  $\mathcal{X}$ if for every starting distribution \( \xi \) the lumped chain \(
  \bar{X}_n \) is a Markov chain with state space $S$ and the
  associated transition probabilities do not depend on the choice of
  $\xi$.  
\end{definition}

The following theorem gives a necessary and sufficient for a Markov
chain to be lumpable.

\begin{theorem}
Denote the transition probability
of the Markov chain $X_n$ from state $x_i$ to state $x_j$, for \( i, j
= 1, \dots,  r\) , by \( p_{ij} \).  A 
necessary and sufficient condition for the Markov chain $X$ to be lumpable
with respect to the partition $S$ is that for every pair of sets
$E_i$ and $E_j$, \( sum_{x_k \in E_j} p_{ik} \) has the
same value for every \(x_i \in E_j \). These common values form
the transition probabilities $\hat{p}_{ij}$ for the lumped chain.
\end{theorem}

\begin{proof}
  \begin{enumerate}
  \item Necessity:
    \begin{enumerate}
    \item 
  For the chain to be lumpable, it is necessary that
\[
  \prob{\bar{X}_1 = E_j \given \bar{X}_0 = E_i} = \probsub{\xi}{X_0
  \in E_i }
\]
be the same for every $\xi$ for which it is defined.    Call this
common value $\hat{p}_{ij}$.
\item   In particular this must be the same for
$\xi$ having a $1$ in its $k$th component for state $x_k \in E_i$.
Hence $p_{kE_j} = \prob{x_i \in A_j} = \hat{p}_{ij}$.  
\item Thus the
condition given is necessary.
\end{enumerate}
\item Sufficiency:
  \begin{enumerate}
  \item The proof must show that if the condition is satisfied, the
    probability 
\[
  \prob{\bar{X}_n = E_t \given \bar{X}_{n-1} = E_{t_{n-1}},
    \bar{X}_{n-2} = E_{t_{n-2}}, \dots,  \bar{X}_1 = E_{t_1},
    \bar{X}_0 = E_i} = \probsub{\xi}{X_0} \in E_i \given X_{n-1} \in E_{t_{n-1}},
    X_{n-2} \in E_{t_{n-2}}, \dots,  X_1 \in E_{t_1},
    X_0 \in E_i}.
\]
depends only on $E_t$ and $E_{t_{n-1}}$.
\item This conditional probability may be written in the form \(
  \probsub{\xi'}{x_1 \in E_t} \) where $\xi'$ is a vector with
  non-zero components only in the sates of $E_{t_{n-1}}$. 
\item This probability depends on $\xi$ and on the first $n$ outcomes.
\item However, if \( \probsub{k}{x_1 \in E_t} = \hat{p}_{t, t_{n_1}}
  \) for all $x_k \in E_t$, then it is clear that $\probsub{\xi'}{x_1
    \in E_t} = \hat{p}_{st}$.
\item Thus the probability depends only on $E_s$ and $E_t$. 
\end{enumerate}
  \end{enumerate}
\end{proof}

\begin{example}
  Recall the example of the weather in the land of Oz, where it is
  rainy, nice or snowy, with probability transition matrix
      \[
        P = \bordermatrix{ & R & N & S \cr
        R & 1/2 & 1/4 & 1/4 \cr
        N & 1/2 & 0 & 1/2 \cr
        S & 1/4 & 1/4 & 1/2 }.
    \]
  Now consider lumping the weather states into only ``good'' days with
  nice weather and ``bad'' days with rainy or snowy weather.  That is,
  choose the partition $S = \set{ \set{N}, \set{R,S}} = \set{G, B}$.
  The probabilities of moving from $R$ to $N$ and from $S$ to $N$ are
  the same so the condition for lumpability is satisfied.  The new
  transition matrix is
  \[
    P = \bordermatrix{ G & B \cr}
    G & 0 & 1 \cr
    B & 1/4 & 3/4}.
\]

On the other hand, notice that the condition for lumpability is not
satisfied for the partition $S = \set{ \set{R}, \set{N, S}}$ since
$p_{N S_1} = p_{NR} = 1/2$ and $p_{N S_1} = p_{SR} = 1/4$.
\end{example}

A matrix formulation of this theorem is useful.
Introduce some notations.
Associated with a partition \( \mathbf{S} = \set{E_1,  E_2, \dots,
  E_v} \) of the finite state space
\( \mathcal{X} = \set{x_1, x_2, \dots,  x_k}\), of the underlying Markov chain $X_n$, introduce
two useful matrices. Let $U$ be the $v \times k$ matrix whose $i$th
row, \( \i =
1, 2, \dots, v \), is the probability vector having equal values for states
in $E_{\xi}$ and $0$ elsewhere. Let $V$ be the $r \times v$ matrix with the $j$th column,
\( j = 1, 2, \dots, v \), is a vector with $1$s in the components corresponding to
states in $E_j$, and $0$ elsewhere.  Then $UV = I$ and the lumped
transition matrix is \( \hat{P} = UPV \).

\begin{example}
  In the previous lumped land of Oz weather example
  \[
    \hat{P} =
    \begin{pmatrix}
      0 & 1 & 0 \\
      1/2 & 0 & 1/2
    \end{pmatrix}
    \begin{pmatrix}
     1/2 & 1/4 & 1/4  \\
     1/2 & 0 & 1/2 \\
       1/4 & 1/4 & 1/2 
   \end{pmatrix}
   \begin{pmatrix}
     0 & 1 \\
     1 & 0 \\
     0 & 1
   \end{pmatrix} =
   \begin{pmatrix}
     0 & 1 \\
     1/4 & 3/4
   \end{pmatrix}
   \]
\end{example}

Note that the rows of $PV$ corresponding to the elements in the same
set of the partition are the same.  This will be true in general for a
chain satisfying the condition for lumpability.  The matrix $U$ simply
removes this duplication of rows.  The choice of $U$ is not unique,
all that is needed is that the $i$th row should be a probability
vecotr with non-zero components only for states in $E_i$.  FOr
convenience, choose the vector with equal components.

It is convenient to assume that the state are ordered so that those
in $E_1$ come first, those in $E_{2}$ come next and so on with those
in $E_r$ coming last.  From here on, assume that this ordering of
states has been made.


\begin{theorem}
  if $P$ is the transition probability matrix of the Markov chain
$X_n$, then $X_n$ is lumpable with respect to the partition $\mathcal{S}$, if and only if
\( VUPV = PV \).
\end{theorem}

\begin{proof}
  \begin{enumerate}
  \item $\Rightarrow$
    \begin{enumerate}
    \item The matrix $VU$ has the block matrix form
      \[
        VU =
        \begin{pmatrix}
          W_1 & 0 & 0 \\
          0   & W_2 & 0 \\
          0   & 0   & W_3
        \end{pmatrix}
      \]
      where $W_1$, $W_2$, and $W_3$ are probability matrices.
    \item The hypothesis that \( VUPV = PV \) means that the columns
      of $PV$ are fixed vectors of $VU$.
    \item Since the chain is lumpable, the probability of moving from a
      state of $E_i$ to the set $E_j$ is the same for all states of
      $A_i$, hence the components of a column of $PV$ corresponding to
      $A_j$ are all the same.
    \item Therefore they form a fixed vector for $W_j$, this proves
      \(VUPV = PV \).
    \end{enumerate}
  \item $\Leftarrow$
    \begin{enumerate}
    \item Assume \(VUPV = PV \).  Then the columns of $PV$ are fixed
      vectors for $VU$.  But each $W_j$ is the transition change of an
      ergodic chain, so its only fixed column vectors are of the form
      $c \mathbf{1}$.  Hence all the components of a column of $PV$ must be
      the same.  That is, the chain is lumpable.
    \end{enumerate}
  \end{enumerate}
\end{proof}

\begin{corollary}
  \[
    \hat{P}^n = U P^n V
  \]
\end{corollary}

\begin{proof}
  From the theorem,
  \[
    \hat{P}^2 = U P V U P V = U P^2 V
  \]
  and the corollary follows by induction.
\end{proof}


\subsection*{Lumping Absorbing Chains}

Assume  now  that  $P$  is  an  absorbing  chain.   Restrict  Our 
attention  to  the  case  of  lumping  only  states  of the  same  kind. 
That is,  any subset of our partition will  contain only absorbing states 
or  only  non-absorbing  states.     Recall  that the  standard form  for 
an absorbing chain is
\[
  P =
  \begin{pmatrix}
    I & 0 \\
    R & Q
  \end{pmatrix}
\]
and write $U$ in the form
\[
  U =
  \begin{pmatrix}
    U_1 & 0 \\
    0  & U_{2}
  \end{pmatrix}
\]
where entries of $U_1$ refer to absorbing states and entries of $U_2$
to non-absorbing states.  Similarly write $V$ in the form
\[
  V 
  \begin{pmatrix}
    V_1 & 0 \\
    0  & V_{2}
  \end{pmatrix}.
\]
In terms of this decomposition, the matrix condition for lumpability
becomes
\begin{align*}
  V_1 U_1 V_1 &= V_1 \\
  V_2 U_2 R V_1 &= R V_1 \\
  V_2 U_2 Q V_2 &= Q V_2
\end{align*}
Since $U_1 V_1 = I$, the first condition is automatically satisfied.
The standard form for the transition matrix $\hat{P}$ is
\[
  \hat{P} = UPV =   \begin{pmatrix}
    U_1 & 0 \\
    0  & U_{2}
  \end{pmatrix}
  \begin{pmatrix}
    I & 0 \\
    R & Q
  \end{pmatrix}
  \begin{pmatrix}
    V_1 & 0 \\
    0  & V_{2}
  \end{pmatrix}.
=   \begin{pmatrix}
    V_1 & 0 \\
    0  & V_{2}
  \end{pmatrix}
  \begin{pmatrix}
    I & 0 \\
    U_2 R V_1 & U_2 Q V_2
  \end{pmatrix}.
\]
Then
\begin{align*}
  \hat{R} &= U_2 R V_1 \\
  \hat{Q} &= U_2 Q V_2
\end{align*}
From $V_2 U_2 Q V_2 = Q V_2$, obtain $\hat{Q}^2 =  U_2 Q V_2 U_2 Q V_2
&= U_2 Q^2 V_2$.

From the infinite series representation for the fundamental matrix $N$
we have
\begin{align*}
  \hat{N} &= I + \hat{Q} + \hat{Q}^2 + \cdots \\
          &= U_2 I V_2+ U_2 Q V_2 + U_2 Q^2 V_2 + \cdots \\
          &= U_2 (I +  Q  +  Q^2 + \cdots) \\
          &= U_2 N V_2.
\end{align*}
From this \( \hat{\tau} = U_2 N V_2 \mathbf{1} = U_2 N  \mathbf{1} =
U_2 \tau\)and
\begin{align*}
  \hat{B} = \hat{N} \hat{R} &= U_2 N V_2 U_2 R V_1 \\
                            &= U_2 N R V_1 \\
                            &= U_2 B V_1.
\end{align*}
So the important absorption quantities are all easily obtained for the
lumped chain from the original chain.

A consequence of $\hat{\tau} = U_2 \tau$ is the following.
Let $E_j$ be any non-absorbing set, and let $x_i$ be a state in
$E_i$.  CHoose the $i$th row of $U_2$ be a probability vecotr with $1$
in the $x_k$ component.  This means that $t_i = t_\ell$ for all $x_\ell$ in
$E_j$.  When a chain is lumpable, the mean time to absorption must be
the same for all starting states in the same set $E_j$

\subsection*{Lumping Ergodic Chains}

Assume the ergodic chain $X$ is lumpable for some partition $S$.  The
resutling chain will be also be ergodic.  Let $\hat{A}$ be th limiting
matrix for the lumped chain.  Then
\begin{align*}
  \hat{A} &= \lim_{\nu \to \infty} \frac{\hat{P} + \hat{P}^2 + \cdots +
            \hat{P}^{\nu}}{\nu} \\
  &= \lim_{\nu \to \infty} \frac{UPV + UP^2V + \cdots +
    UP^{\nu}V}{\nu} \\
  & = UAV.
\end{align*}
This states that the components of $\hat{\alpha}$ are obtained from
$\alpha$ by simply adding the components of a given set.  From the
infinite series represnetation for the fundamental matrix $\hat{Z}$
\[
  \hat{Z} = U Z V/
\]
In general, there is no simple relation between $M$ and $\hat{M}$.
However, the mean time to go from state $x_i$ in $E_j$ to $E_{\ell}$
in the original process is the same for all states in $E_i$.  
\subsection*{Examples}

\begin{example}
    Consider a random walk%
    \index{random walk}
    of a particle which moves along a straight line in unit steps.  Each
    step is \( 1 \) unit to the right with probability \( \frac{1}{2} \) and to
    the left with probability \( \frac{1}{2} \).  It moves until it reaches
    one of two extreme points which are \defn{absorbing boundaries}.~%
    \index{absorption probability matrix}
    Assume that if the process reaches the boundary points, it remains
    there from that time on.  Figure~%
    \ref{fig:waitingtimeabsorbtion:randomwalkphasespace} has \( 9 \)
    states numbered from \( -4 \) to \( 4 \).  The absorbing boundary
    states are \( -4 \) and \( 4 \).

    In the small case the state space has $5$ values with absorbing
    boundary states $x_1$ and $x_5$ and using the ordering for the
    standard form the transition matrix is
    \[
      P =
      \bordermatrix{
       & s_1 & s_5 & s_2 & s_3 & s4 \cr
      s_1 1 & 0 & 0 & 0 & 0 \cr
      s_5 0 & 1 & 0 & 0 & 0 \cr
      s_2 1/2 & 0 & 0 1/2 & 0 \cr
      s_3 0 & 0 1/2 & 0 & 1/2 \cr
      s_4 ) & 0 & 0 1/2 & 0 \cr
    }
  \]
  Take the partition $S = \set{ \set{s_1, s_5}, \set{s_2, s_4},
    \set{s_3}}$.  For  this  partition 
the condition for lumpabiIity is  satisfied, Notice  that this would not 
have  been the case  if we  have  unequal probabilities for  moving
to left or right.

It is easy to verify that
\begin{align*}
   \hat{P} &=
   \begin{pmatrix}
     1 & 0 & 0 \\
     1/2 & 0 & 1/2 \\
     0  & 1  & 0
   \end{pmatrix} \\
  \hat{N} &=
  \begin{pmatrix}
    2 & 1 \\
    2 & 2
  \end{pmatrix} \\
  \hat{\tau} &= (3, 4)^T \\
  \hat{B} &= (1,1)^T.
\end{align*}
 

\visual{Section Starter Question}{../../../../CommonInformation/Lessons/question_mark.png}
\section*{Section Ending Answer}

\subsection*{Sources}
This section is adapted from: 

\nocite{}
\nocite{}

\hr

\visual{Algorithms, Scripts, Simulations}{../../../../CommonInformation/Lessons/computer.png}
\section*{Algorithms, Scripts, Simulations}

\subsection*{Algorithm}

\subsection*{Scripts}

\input{ _scripts}

\hr

\visual{Problems to Work}{../../../../CommonInformation/Lessons/solveproblems.png}
\section*{Problems to Work for Understanding}
\renewcommand{\theexerciseseries}{}
\renewcommand{\theexercise}{\arabic{exercise}}

\begin{exercise}
  
\end{exercise}
\begin{solution}
  
\end{solution}
\begin{exercise}
  \begin{enumerate}[label=(\alpha*)]
  \item 
  \end{enumerate}
\end{exercise}
\begin{solution}
  \begin{enumerate}[label=(\alpha*)]
  \item 
  \end{enumerate}
\end{solution}

\hr

\visual{Books}{../../../../CommonInformation/Lessons/books.png}
\section*{Reading Suggestion:}

\bibliography{../../../../CommonInformation/bibliography}

%   \begin{enumerate}
%     \item 
%     \item 
%     \item 
%   \end{enumerate}

\hr

\visual{Links}{../../../../CommonInformation/Lessons/chainlink.png}
\section*{Outside Readings and Links:}
\begin{enumerate}
  \item  
  \item  
  \item  
  \item 
\end{enumerate}

\section*{\solutionsname}
\loadSolutions

\hr

\mydisclaim \myfooter

Last modified:  \flastmod

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
