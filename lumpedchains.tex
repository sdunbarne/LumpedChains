%%% -*-LaTeX-*-
%%% lumpedchains.tex.orig
%%% Prettyprinted by texpretty lex version 0.02 [21-May-2001]
%%% on Wed Sep 28 09:19:46 2022
%%% for Steve Dunbar (sdunbar@family-desktop)

\documentclass[12pt]{article}

\input{../../../../etc/macros} %\input{../../../../etc/mzlatex_macros}
\input{../../../../etc/pdf_macros}

\bibliographystyle{plain}

\begin{document}

\myheader \mytitle

\hr

\sectiontitle{Lumped Markov Chains}

\hr

\usefirefox

\hr

% \visual{Study Tip}{../../../../CommonInformation/Lessons/studytip.png}
% \section*{Study Tip}

% \hr

\visual{Rating}{../../../../CommonInformation/Lessons/rating.png}
\section*{Rating} %one of
% Everyone: contains no mathematics.
% Student: contains scenes of mild algebra or calculus that may require guidance.
Mathematically Mature:  may contain mathematics beyond calculus with
proofs.  % Mathematicians Only: prolonged scenes of intense rigor.

\hr

\visual{Section Starter Question}{../../../../CommonInformation/Lessons/question_mark.png}
\section*{Section Starter Question}

The weather in the land of Oz, where it is either rainy, nice or snowy,
has probability transition matrix
\[
    P = \bordermatrix{ & R & N & S \cr
    R & 1/2 & 1/4 & 1/4 \cr
    N & 1/2 & 0 & 1/2 \cr
    S & 1/4 & 1/4 & 1/2 }.
\] Consider lumping the weather states into only ``good'' days with nice
weather and ``bad'' days with rainy or snowy weather.  What is the
probability of going from a bad weather day to a bad weather day?

\hr

\visual{Key Concepts}{../../../../CommonInformation/Lessons/keyconcepts.png}
\section*{Key Concepts}

\begin{enumerate}
    \item
        Denote the transition probability of the Markov chain \( X_n \)
        from state \( x_i \) to state \( x_j \), for \( i, j = 1, \dots,
        k \), by \( P_{ij} \).  A necessary and sufficient condition for
        the Markov chain \( X_n \) to be lumpable with respect to the
        partition \( S \) is that for every pair of sets \( E_{\xi} \)
        and \( E_{\eta} \), \( \sum_{x_{\nu} \in E_{\eta}} P_{i,\nu} \)
        has the same value for every \( x_i \in E_{\xi} \).  These
        common values form the transition probabilities \( P_{\xi, \eta}
        \) for the lumped chain.
    \item
        The \defn{distributing matrix}%
        \index{distributing
  matrix}
        \( U \) is the wide \( v \times k \) matrix with entries
        \[
            U_{ij} =
            \begin{cases}
                \pi_j/\sum_{\nu \in E_j} \pi_\nu & x_j \in E_j \\
                0 & \text{otherwise}.
            \end{cases}
        \] The rows of the distributing matrix are the stationary
        distribution restricted to \( E_j \) and renormalized so its
        entries add to \( 1 \).  Let the \defn{collecting matrix}%
        \index{collecting matrix}
        \( V \) be the tall \( k \times v \) matrix with the \( j \)th
        column, \( j = 1, 2, \dots, v \), is a vector with \( 1 \)s in
        the components corresponding to states in \( E_j \), and \( 0 \)
        elsewhere.  The collecting matrix specifies the lumped
        probability distribution \( \hat{P} = P V \) on the partition \(
        E \).
    \item
        If \( P \) is the transition probability matrix of the Markov
        chain \( X_n \), then \( X_n \) is lumpable with respect to the
        partition \( \mathcal{S} \), if and only if \( VUPV = PV \).
    \item
        Let \( \delta = \| VUP - P \|_{\pi} \).  Then
        \[
            \| (VUP)^n - P^n \|_{\pi} < K(n) \delta < {K} \delta
        \] with \( K(n) = n \abs{\lambda_2}^{n-1} \), where \( \lambda_2
        \) is the second largest eigenvalue of \( P \) and \( \hat{K} =
        -1/(\lambda_2 \cdot \EulerE \cdot \log(\lambda_2)) \).
\end{enumerate}

\hr

\visual{Vocabulary}{../../../../CommonInformation/Lessons/vocabulary.png}
\section*{Vocabulary}
\begin{enumerate}
    \item
        Let \( X_n \) be a Markov chain with state space \( \mathcal{X}
        = \set{x_1, x_2, \dots, x_k} \) and initial distribution \( X_0 \).
        Given a partition \( \hat{S} = \set{E_1, E_2, \dots, E_v} \) of
        the state space \( S \), define a new stochastic process \( \hat
        {X}_n \) as follows:  At the \( j \)th step, the state of the
        new chain is the set \( E_\ell \) when \( E_\ell \) contains the
        state of the \( j \)th step of the original chain.  Assign the
        transition probabilities for \( \hat{X}_n \) as follows:  The
        initial distribution is
        \[
            \Prob{\hat{X}_0 = E_{\xi}} = \Probsub{X_0}{x_0 \in E_{\xi}}.
        \] Given the initial state, the transition probability for step \(
        1 \) is
        \[
            \Prob{\hat{X}_1 = E_{\eta} \given \hat{X}_0 = E_{\xi}} =
            \Probsub{X_0} {X_1 \in E_{\eta} }.
        \] In general for the \( n \)th step
        \begin{multline*}
            \Prob{\hat{X}_n = E_{\eta} \given \hat{X}_{n-1} = E_{\eta_{n-1}},
            \hat{X}_{n-2} = E_{\eta_{n-2}}, \dots, \hat{X}_1 = E_{\eta_1},
            \hat{X}_0 = E_\xi} \\
            = \Probsub{X_0}{X_n \in E_{\eta} \given X_{n-1} \in E_{\eta_
            {n-1}}, X_{n-2} \in E_{\eta_{n-2}}, \dots, X_1 \in E_{\eta_1},
            X_0 \in E_{\xi}}.
        \end{multline*}
        Call this new stochastic process, \( \hat{X}_n \), a \defn{lumped
        chain}%
        \index{lumped chain}
        of the Markov chain \( X_n \).  Sometimes this is also called a
        \emph{projection} of the Markov chain \( X_n \).
    \item
        A Markov chain with \( X_n \) state space with state space \(
        \mathcal{X} \) is said to be \defn{lumpable}%
        \index{lumpable}
        with respect to a partition \( \hat{S} \) of \( \mathcal{X} \)
        if for every starting distribution \( X_0 \) the lumped process \(
        \hat{X}_n \) is a Markov chain with state space \( \hat{S} \)
        and the associated transition probabilities do not depend on the
        choice of \( X_0 \).
    \item
        The \defn{distributing matrix}%
        \index{distributing
  matrix}
        \( U \) is the \( v \times k \) matrix with entries
        \[
            U_{ij} =
            \begin{cases}
                \pi_j/\sum_{\nu \in E_i} \pi_\nu & x_j \in E_i \\
                0 & \text{otherwise}.
            \end{cases}
        \] The \( i \)th row of the distributing matrix is the
        stationary distribution restricted to \( E_i \) and renormalized
        so its entries add to \( 1 \).
    \item
        Let the \defn{collecting matrix}%
        \index{collecting matrix}
        \( V \) be the \( k \times v \) matrix with the \( j \)th
        column, \( j = 1, 2, \dots, v \), is a vector with \( 1 \) in
        the components corresponding to states in \( E_j \), and \( 0 \)
        elsewhere.  The collecting matrix specifies the lumped
        probability distribution \( \hat{p} = p V \) on the partition \(
        E \).
\end{enumerate}

\section*{Notation}
\begin{enumerate}
    \item
        \( X_n \) -- discrete time, discrete space Markov chain
    \item
        \( \mathcal{X} = \set{x_1, x_2, \dots, x_k} \) -- state space
    \item
        \( k \) -- number of states in the Markov chain
    \item
        \( x_i, x_j \) -- generic states of Markov chain
    \item
        \( P \) -- \( k \times k \) transition probability matrix
    \item
        \( p_{ij} \) -- entry in the transition matrix
    \item
        \( X_0 \) -- initial distribution or state of the Markov chain,
        with abuse of notation for the same notation to represent both
        an initial probability distribution over the states and the
        single state corresponding to a delta-distribution (certainty)
        on that state
    \item
        -- \( \pi \) -- stationary probability distribution
    \item
        \( \hat{S} = \set{E_1, E_2, \dots, E_v} \) -- a partition of the
        state space \( \mathcal{X} \) into equivalence classes
    \item
        \( v \) -- number of states in the lumped chain
    \item
        \( E_{\xi}, E_{\eta} \) -- generic state of the lumped chain
        with \( E_{\xi} \) the source and \( E_{\eta} \) the
        destination.
    \item
        \( \hat{X}_n \) -- a lumped process
    \item
        \( \hat{\pi} \) -- lumped chain stationary distribution
    \item
        \( U \) and \( V \) -- distributing matrix and collecting matrix
        respectively
    \item
        \( p, q \) -- probability distributions on \( \mathcal{X} \)
    \item
        \( \hat{p} \) -- corresponding probability distribution on \(
        \hat{S} \)
    \item
        \( I_v \) -- \( v \times v \) identity matrix
    \item
        \( W_i \) -- submatrices of \( VU \)
    \item
        \( I, R, Q \) -- submatrices of absorbing chain transition
        probability matrix \( P \)
    \item
        \( U_1, U_2, V_1, V_2 \) -- submatrices of \( U, V \)
    \item
        \( \hat{N}, \hat{\tau}, \hat{B} \) -- normal matrix and
        absorption quantities for lumped chain
    \item
        \( Q^k, E(Q^k), V(Q^k) \) -- \( k \)-dimensional hypercube as a
        graph, with the edge and vertex sets of the graph
    \item
        \( \| v \|_{\pi} \) -- vector norm related to \( \pi \)
    \item
        \( D_{\sqrt{\pi}} \) -- diagonal matrix related to \( \pi \)
    \item
        \( H = VUP \) -- matrix used for bounding norm difference
    \item
        \( P_{\pi}, P_{\Sigma} \) -- projection matrices
    \item
        \( \Sigma \) -- subspace complementary to span of \( \pi \)
    \item
        \( \delta \) -- initial norm difference
    \item
        \( \lambda_2 \) -- second largest eigenvalue
    \item
        \( K(n), \hat{K} \) -- upper bounds on norm difference
    \item
        \( \nu \) -- A dummy variable of summation, no meaning, meant to
        mimic the counting variable \( n \)
\end{enumerate}

\hr

\visual{Mathematical Ideas}{../../../../CommonInformation/Lessons/mathematicalideas.png}
\section*{Mathematical Ideas}

Partitioning the states of a Markov chain into equivalence classes or
lumps and viewing the dynamics at a coarser level as the system of
interest moves among the lumps is often convenient.  Examples of such
aggregation include a weather model lumping the states ``rain'' and
``snow'' into one state called ``bad weather'' or a physical model
aggregating the microstates of a physical system into coarse grained
``mesostates'' representing many microstates.  Other examples are
reducing the size of the PageRank matrix used in web searches, and
modeling clusters or ``communities'' in networks.

Although the dynamics moving among the lumps is not necessarily
Markovian in general, there is a natural requirement for a Markov chain
model on the set of lumped states.  This requirement matches the time
evolution of the original unlumped chain started at equilibrium.  This
provides bounds on the error of the dynamics predicted by the lumped
chain considered as a model of the unlumped chain.  The goal in this
section is to analyze the accuracy of such coarse grained models
compared to the exact microscopic behavior, i.e.\ to bound the error in
a coarse grained description.

\subsection*{Lumpable Markov Chains}

%% https://www.math.pku.edu.cn/teachers/yaoy/Fall2011/Kemeny-Snell_Chapter6.3-4.pdf
%% https://web.nmsu.edu/~jtian/PB/2006-3.pdf
%% https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3207820/
%% http://www.sci.sdsu.edu/~salamon/OLPpublished.pdf

\begin{definition}
    Let \( X_n \) be a Markov chain with state space \( \mathcal{X} =
    \set{x_1, x_2, \dots, x_k} \) and initial distribution \( X_0 \).
    Given a partition \( \hat{S} = \set{E_1, E_2, \dots, E_v} \) of the
    state space \( \mathcal{X} \) into equivalence classes, define a new
    stochastic process \( \hat{X}_n \) as follows:  At the \( j \)th
    step, the state of the new chain is the set \( E_{\xi} \) when \( E_
    {\xi} \) contains the state of the \( j \)th step of the original
    chain.  Think of the notations \( \hat{X}_n \) and \( \hat{S} \) as
    ``heaping up'' the chain into the lumps.  Assign the transition
    probabilities for \( \hat{X}_n \) as follows:  The initial
    distribution is
    \[
        \Prob{\hat{X}_0 = E_{\xi}} = \Probsub{X_0}{x_0 \in E_{\xi}}.
    \] Given the initial state, the transition probability for the first
    step is
    \[
        \Prob{\hat{X}_1 = E_{\eta} \given \hat{X}_0 = E_{\xi}} =
        \Probsub{X_0}{X_1 \in E_{\eta} }.
    \] In general for the \( n \)th step
    \begin{multline*}
        \Prob{\hat{X}_n = E_{\eta} \given \hat{X}_{n-1} = E_{\eta_{n-1}},
        \hat{X}_ {n-2} = E_{\eta_{n-2}}, \dots, \hat{X}_1 = E_{\eta_1},
        \hat{X}_0 = E_\xi}\\
        = \Probsub{X_0}{x_n \in E_j \given x_{n-1} \in E_{t_{n-1}}, x_{n-2}
        \in E_{t_{n-2}}, \dots, x_1 \in E_{t_1}, x_0 \in E_i}.
    \end{multline*}
    Call this new process \( \hat{X}_n \) a lumped process and if the
    lumped process is a Markov chain, it is a \defn{lumped chain}.%
    \index{lumped chain}
    of the Markov chain \( X_n \).  Sometimes this is also called a
    \emph{projection} of the Markov chain \( X_n \).%
    \index{projection}
\end{definition}
Figure~%
\ref{fig:lumpedchains:schematic} has a schematic diagram of a lumped
Markov chain. A lumped process of a given Markov chain need not be a
Markov chain in general, see the second example below.

\begin{figure}
    \centering
\begin{asy}
size(5inches);

real myfontsize = 12;
real mylineskip = 1.2*myfontsize;
pen mypen = fontsize(myfontsize, mylineskip);
defaultpen(mypen);

pair A = (-2, 2);
pair B = (-1, 2);
pair C = (-2, 1);
pair D = (-1, 1);
pair E1 = (-1.5, 1.5);

pair Ee = ( 1, 2);
pair F = ( 2, 2);
pair G = ( 1, 1);
pair E2 = (1.5, 1.5);

pair H = (-1,-1);
pair J = (-2,-2);
pair Ii = (-1,-3);
pair K = ( 0,-2);

pair L = ( 1,-1);
pair M = ( 1,-2);
pair E3 = (-0.3, -2);

dot("$x_1$", A, N); dot("$x_2$", B, N);
dot("$x_3$", C, S); dot("$x_4$", D, SW);

dot("$x_5$", Ee, N); dot("$x_6$", F, N);
dot("$x_7$", G, S);

dot("$x_8$", H, W); dot("$x_{13}$", L, W);
dot("$x_{10}$", Ii, E); dot("$x_{11}$", K, SE); dot("$x_{12}$", M, S);
dot("$x_{9}$",J, W);

draw(B--A--C--D--A--B--C);
draw(Ee--F--G--cycle);
draw(H--K--J--Ii--H--J--Ii--K);
draw(K--M--L);

draw(H--D);
draw(B--G);
draw(L--F);

filldraw(circle(E1, 0.9), fillpen=red+opacity(0.4));
filldraw(circle(E2, 0.9), fillpen=lightblue+opacity(0.4));
filldraw(ellipse(E3, 2.1,1.45), fillpen=green+opacity(0.4));

label("$E_1$", E1+1.0*N);
label("$E_2$", E2+1.0*N);
label("$E_3$", E3+1.55*N);
\end{asy}

    \caption{A schematic diagram of a lumped Markov chain.}%
    \label{fig:lumpedchains:schematic}
\end{figure}

\begin{definition}
    A Markov chain with \( X_n \) with state space \( \mathcal{X} \) is
    said to be \defn{lumpable}%
    \index{lumpable}
    \index{Markov chain!lumpable}
    with respect to a partition \( \hat{S} \) of \( \mathcal{X} \) if
    for every starting distribution \( X_0 \) the lumped chain \( \hat{X}_n
    \) is a Markov chain with state space \( \hat{S} \) and the
    associated transition probabilities do not depend on the choice of \(
    X_0 \).
\end{definition}

The following theorem gives a necessary and sufficient condition for a
Markov chain to be lumpable.

\begin{theorem}
    Denote the transition probability of the Markov chain \( X_n \) from
    state \( x_i \) to state \( x_j \), for \( i, j = 1, \dots, k \), by
    \( P_{ij} \).  The Markov chain \( X_n \) is lumpable with respect
    to the partition \( \hat{S} \) if and only if for every pair of sets
    \( E_{\xi} \) and \( E_{\eta} \), \( \sum_{x_{\nu} \in E_{\eta}} P_{i\nu}
    \) has the same value for every \( x_i \in E_{\xi} \).  These common
    values form the transition probabilities \( \hat{P}_{\xi \eta} \)
    for the lumped chain.
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item[\( (\Rightarrow) \)]
            \begin{enumerate}
                \item
                    If the chain is lumpable, then
                    \[
                        \Prob{\hat{X}_1 = E_{\eta} \given \hat{X}_0 = E_
                        {\xi}} = \Probsub{X_0}{X_1 \in E_{\eta} }
                    \] is the same for every \( X_0 \) for which it is
                    defined.  Call this common value \( \hat{P}_{\xi,\eta}
                    \).
                \item
                    In particular this must be true for \( X_0^{(\nu)} \)
                    having a \( 1 \) in its \( \nu \)th component for
                    state \( x_{\nu} \in E_{\xi} \).  Hence \( \Probsub{X_0^
                    {(\eta)}}{x_{j} \in E_j} = \sum_{x_\nu \in E_{\eta}}
                    P_{i \nu } \) has the same value \( \\
                    hat{P}_{ij} \) for every \( x_i \in E_{\xi} \).
            \end{enumerate}
        \item[\( (\Leftarrow) \)]
            \begin{enumerate}
                \item
                    The proof must show that if the lumpability
                    condition is satisfied, the probability
                    \[
                        \Prob{\hat{X}_n = E_\eta \given \hat{X}_{n-1} =
                        E_{\eta_ {n-1}}, \hat{X}_{n-2} = E_{\eta_{n-2}},
                        \dots, x_1 \in E_{\eta_{1}}, \hat{X}_0 = E_\xi}
                    \] depends only on \( E_\eta \) and \( E_{\eta_{n-1}}
                    \).
                \item
                    By definition, the probability in question is
                    \[
                        \Probsub{X_0} {x_n \in E_\eta \given x_{n-1} \in
                        E_{\eta_{n-1}}, x_{n-2} \in E_{\eta_{n-2}},
                        \dots, x_1 \in E_{\eta_{1}}}.
                    \]
                \item
                    By the Markov memory-less property, this conditional
                    probability may be written in the form \( \Probsub{\xi'}
                    {x_n \in E_\eta} \) where \( \xi' \) is a
                    probability vector with nonzero components only in
                    the states of \( E_{\eta_{n-1}} \).
                \item
                    This probability depends on the states in \( E_{\eta}
                    \) and on the states in \( E_{\eta_{n-1}} \).
                \item
                    By the hypothesis of the lumpability condition, \(
                    \Probsub{\xi'}{x_n \in E_\eta} \) where \( \xi' \)
                    is a probability vector with nonzero components only
                    in the states of \( E_{\eta_{n-1}} \) is \( \hat{P}_
                    {\eta_{n-1} \eta} \), independent of state \( x_{n-1}
                    \in E_{\eta_{n-1}} \).
                \item
                    Thus the probability depends only on \( E_\eta \)
                    and \( E_{\eta_{n-1}} \).
            \end{enumerate}
    \end{enumerate}
\end{proof}

\begin{example}
    Recall the example of the weather in the land of Oz, where it is
    rainy, nice or snowy, with probability transition matrix
    \[
        P = \bordermatrix{ & R & N & S \cr
        R & 1/2 & 1/4 & 1/4 \cr
        N & 1/2 & 0 & 1/2 \cr
        S & 1/4 & 1/4 & 1/2 }.
    \] Now consider lumping the weather states into only ``good'' days
    with nice weather and ``bad'' days with rainy or snowy weather.
    That is, choose the partition \( \hat{S} = \set{ \set{N}, \set{R,S}}
    = \set{G, B} \).  The probabilities of moving from \( R \) to \( N \)
    and from \( S \) to \( N \) are the same.  The complementary
    probabilities of moving from \( R \) or \( S \) to \( \set{R, S} \)
    are each the same.  The probability of moving from \( N \) to \(
    \set{R, S} \) or \( \set{N} \) is trivially the same for all states
    in \( G \).  This weather Markov chain satisfies the lumpability
    condition.  The lumped transition probability matrix is
    \[
        P = \bordermatrix{ & G & B \cr
        G & 0 & 1 \cr
        B & 1/4 & 3/4}.
    \] By direct computation the stationary distribution on the lumped
    chain is \( (1/5, 4/5) \), as expected from lumping the stationary
    distribution of the original weather chain.

    On the other hand, the lumpability condition is not satisfied for
    the partition \( \set{ \set{R}, \set{N, S}} \) since \( P_ {N \set{N,
    S}} = 1/2 \) but \( P_{S \set{N,S}} = 3/4 \).
\end{example}

\begin{example}
    An arbitrary lumping of states of a Markov chain does not
    necessarily lead to a Markov chain.  Let \( X_n \) be a Markov chain
    with state space \( \mathcal{X} = \set{1, 2, 3} \) with \( X_0 = 2 \)
    (or as a probability distribution, \( X_0 = (0,1,0) \)) and
    transition probability matrix
    \[
        P =
        \begin{pmatrix}
            0.8 & 0.1 & 0.1 \\
            0.2 & 0.7 & 0.1 \\
            0 & 0.1 & 0.9
        \end{pmatrix}
        .
    \] Then lump the states as \( E_1 = \set{1} \) and \( E_2 = \set{2,3}
    \).  First,
    \[
        \Prob{\hat{X}_1 = E_2 \given \hat{X}_0} = \Probsub{X_0}{X_1 =
        2,3} = 0.7 + 0.1 = 0.8
    \] and
    \begin{multline*}
        \Prob{\hat{X}_2 = E_2, \hat{X}_1 = E_2 \given \hat{X}_0 } = \\
        \Probsub{X_0}{X_2 \ge 2, X_1 = 2} + \Probsub{X_0}{X_2 \ge 2, X_1
        = 3} = \\
        (0.7 + 0.1) \cdot 0.7 + (0.9 + 0.1) \cdot 0.1 = 0.66.
    \end{multline*}
    Second,
    \[
        \Prob{\hat{X}_2 = E_2, \hat{X_1} = E_1} = \Probsub{X_0}{ X_2 \ge
        2, X_1 = 1} = 0.2 \cdot (0.1 + 0.1) = 0.04.
    \] Combining probabilities for these two paths
    \[
        \Prob{\hat{X}_2 = E_2} = \Prob{\hat{X}_2 =E_2, \hat{X}_1 = E_2}
        + \Prob{\hat{X}_2=E_2, \hat{X}_1 = E_1} = 0.7.
    \] Next consider the three step paths
    \begin{multline*}
        \Prob{\hat{X}_3 = E_2, \hat{X}_2=E_2, \hat{X}_1=E_1} = \\
        \Probsub{X_0}{X_1=1, X_2=2, X_3 \ge 2} + \Prob{X_1=1, X_2=3, X_3
        \ge 2} = \\
        0.2 \cdot 0.1 \cdot (0.7+0.1) + 0.2 \cdot 0.1 \cdot (0.1+0.9) =
        0.036.
    \end{multline*}
    and
    \begin{multline*}
        \Prob{\hat{X}_3 = E_2, \hat{X}_2=E_2, \hat{X}_1=E_2} = \\
        \Probsub{X_0}{X_3 \ge 2, X_2=2, X_1=2} + \Probsub{X_0}{X_3 \ge
        2, X_2=3, X_1=2} +\\
        \qquad \Probsub{X_0}{X_3 \ge 2, X_2=2, X_1=3} + \Probsub{X_0}{X_3
        \ge 2, X_2=3, X_1=3} = \\
        0.7 \cdot 0.7 \cdot (0.7 + 0.1) + 0.7 \cdot 0.1 \cdot (0.1 + 0.9)
        + \\
        0.1 \cdot 0.1 \cdot (0.7 + 0.1) + 0.1 \cdot 0.9 \cdot (0.1 + 0.9)
        = 0.56.
    \end{multline*}
    Combining the previous two probabilities
    \[
        \Prob{\hat{X}_3 = E_2, \hat{X}_2 = E_2} = 0.56 + 0.036 = 0.596
    \] so
    \[
        \Prob{\hat{X}_3=E_2 \given \hat{X}_2 = E_2} = 0.596/0.7 \approx
        0.8514
    \] but
    \[
        \Prob{\hat{X}_3 = E_2 \given \hat{X}_2 = 2, \hat{X}_1=E_2} =
        0.56/0.66 \approx 0.8485
    \] showing that \( \hat{X}_k \) is not a Markov chain.
\end{example}

A matrix formulation of this theorem for irreducible and aperiodic
chains is useful.  Introduce some notations.  Introduce two useful
matrices associated with a partition \( \hat{S} = \set{E_1, E_2, \dots,
E_v} \) of the finite state space \( \mathcal{X} = \set{x_1, x_2, \dots,
x_k} \), of the underlying Markov chain \( X_n \) which is assumed to be
irreducible and aperiodic.  The Markov chain has a unique stationary
distribution \( \pi \).  The \defn{distributing matrix}%
\index{distributing
  matrix}
\( U \) is the wide \( v \times k \) matrix with entries
\[
    U_{ij} =
    \begin{cases}
        \pi_j/\sum_{x_{\nu} \in E_i} \pi_\nu & x_j \in E_i \\
        0 & \text{otherwise}.
    \end{cases}
\] The \( i \)th row of the distributing matrix is the stationary
distribution restricted to \( E_i \) and renormalized so its entries add
to \( 1 \).

Let the \defn{collecting matrix}%
\index{collecting matrix}
\( V \) be the tall \( k \times v \) matrix where the \( j \)th column, \(
j = 1, 2, \dots, v \), is a vector with \( 1 \)s in the components
corresponding to states in \( E_j \), and \( 0 \) elsewhere.  For any
probability distribution \( p \) on \( \mathcal{X} \) the collecting
matrix specifies the lumped probability distribution \( \hat{p} = p V \)
on the partition \( \hat{S} \).  Then \( UV = I_v \) since \( V \)
simply collects back exactly what \( U \) distributes.  The lumped
transition matrix is \( \hat{P} = UPV \).

For any probability distribution \( q \) in the lumped space, the image \(
qU \) is locally equilibrated, i.e.\ \( qU \) restricted to any element \(
E_j \) of the partition equals the stationary distribution restricted to
\( E_j \) and renormalized to add to \( q_j \).  In particular, with \(
\hat{\pi} = \pi V \)
\[
    U_{ij} = V_{ji} \frac{\pi_j}{\hat{\pi}_{i}}, \quad i = 1, \dots, k,
    j = 1, \dots, v
\] whose \( i \)th row, \( i = 1, 2, \dots, v \), is the probability
vector having equal values for states in \( E_{\xi} \) and \( 0 \)
elsewhere.  See the exercises.

Note that the rows of \( PV \) corresponding to the elements in the same
set of the partition are the same.  See the following example with the
weather Markov chain.  This will be true in general for a chain
satisfying the condition for lumpability.  The matrix \( U \) simply
removes this duplication of rows.  Again, see the following example with
the weather Markov chain.  The choice of \( U \) is not unique, all that
is needed is that the \( i \)th row should be a probability vector with
nonzero components only for states in \( E_i \).  (See the exercises for
an example with an absorbing chain without a stationary distribution \(
\pi \).) Sometimes for simplicity and convenience, choose the vector
with equal components.

Next consider the local equilibration operator \( VU \).  The name is
justified by considering its action.  Starting from any distribution \(
p \) on \( \mathcal{X} \), \( VU \) collects the probability in each \(
E_j \), then redistributes this much probability \( pV \) among the
lumped states in the partition member \( E_j \) as \( (pU)_j \hat{\pi}_i
\).  In particular,
\[
    \pi = \pi VU.
\]

\begin{example}
    For the land of Oz weather example with
    \[
        \begin{pmatrix}
            1/2 & 1/4 & 1/4 \\
            1/2 & 0 & 1/2 \\
            1/4 & 1/4 & 1/2
        \end{pmatrix}
        ,
    \] recall the stationary distribution is \( \pi = (2/5, 1/5, 2/5) \).
    With the partition \( \hat{S} = \set{ \set{N}, \set{R,S}} =\set{G, B}
    \) the distributing matrix is
    \[
        U =
        \begin{pmatrix}
            0 & 1 & 0 \\
            1/2 & 0 & 1/2
        \end{pmatrix}
        .
    \] For the probability distribution \( q = (2/3, 1/3) \) on the
    lumped space, \( qU = (1/6, 2/3, 1/6) \), so that the \( 1/3 \)
    probability of being in the bad weather state is distributed
    proportionally according to the stationary distribution over the \(
    R \) and \( S \) states.  This explains why \( U \) is called the
    distributing matrix.

    The collecting matrix is
    \[
        V=
        \begin{pmatrix}
            0 & 1 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix}
        .
    \] For the probability distribution \( p = (1/6, 1/12, 3/4) \) on \(
    \set{R,N,S} \), the lumped probability distribution \( \set{G, B} \)
    is \( \hat{p} = pV = (1/12, 11/12) \).  In particular,
    \[
        \left( \frac{1}{5}, \frac{4}{5} \right) = \hat{\pi} = \pi V =
        \left( \frac{2}{5}, \frac{1}{5}, \frac{2}{5} \right)
        \begin{pmatrix}
            0 & 1 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix}
        .
    \] The equality \( UV = I_2 \) is easy to check.

    The lumped weather transition probability matrix is
    \[
        \hat{P} = UPV =
        \begin{pmatrix}
            0 & 1 & 0 \\
            1/2 & 0 & 1/2
        \end{pmatrix}
        \begin{pmatrix}
            1/2 & 1/4 & 1/4 \\
            1/2 & 0 & 1/2 \\
            1/4 & 1/4 & 1/2
        \end{pmatrix}
        \begin{pmatrix}
            0 & 1 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix}
        =
        \begin{pmatrix}
            0 & 1 \\
            1/4 & 3/4
        \end{pmatrix}
        .
    \]

    For the probability distribution \( q = (5/6, 1/6) \) on the lumped
    weather, the image \( qU = (1/12, 5/6, 1/12) \). Restricting \( qU \)
    to element \( B \) of the partition gives \( (1/12, 1/12) \), the
    uniform distribution \( (2/5, 2/5) \) of the stationary distribution
    on \( B \) renormalized to total \( 1/6 \).

    As an example of
    \[
        U_{ij} = V_{ji} \frac{\pi_j}{\hat{\pi}_{i}}, \quad i = 1, \dots,
        v, j = 1, \dots, k
    \] consider \( U_{21} = 1/2 \) while \( V_{12} \frac{\pi_1}{\hat{\pi}_
    {2}} = 1 \cdot \frac{2/5}{4/5} = 1/2 \).

    The rows of
    \[
        PV =
        \begin{pmatrix}
            1/4 & 3/4 \\
            0 & 1 \\
            1/4 & 3/4
        \end{pmatrix}
    \] corresponding to the \( R \) and \( S \) states in \( B \) are
    the same.  Then multiplying by \( U \) removes the duplication and
    illustrates why the rows of \( U \) only need to be a probability
    vector with nonzero components only for states in \( G \) or \( B \).
\end{example}

It is convenient to assume that the state are ordered so that those in \(
E_1 \) come first, those in \( E_{2} \) come next and so on with those
in \( E_v \) last.  From here on, assume that this ordering of states
has been made.

\begin{theorem}
    If \( P \) is the transition probability matrix of the Markov chain \(
    X_n \), then \( X_n \) is lumpable with respect to the partition \(
    \hat{S} \) if and only if \( VUPV = PV \).
\end{theorem}

\begin{proof}
    \begin{enumerate}
        \item
            \( (\Rightarrow) \)
            \begin{enumerate}
                \item
                    The matrix \( VU \) has the block matrix form
                    \[
                        VU =
                        \begin{pmatrix}
                            W_1 & \cdots & 0 \\
                            \vdots & \ddots & \vdots \\
                            0 & \cdots & W_v
                        \end{pmatrix}
                    \] where \( W_1 \), \( W_2 \), \dots, \( W_v \) are
                    probability matrices.
                \item
                    Since the chain is lumpable, the probability of
                    moving from a state of \( E_i \) to the set \( E_j \)
                    is the same for all states of \( E_i \), hence the
                    components of a column of \( PV \) corresponding to \(
                    E_j \) are all the same.
                \item
                    Say that common value of probability is \( \rho_j \),
                    so a column of \( PV \) is \( \rho_j \) in the
                    entries corresponding to \( E_j \) and \( 0 \)
                    elsewhere.
                \item
                    Then multiplying by \( VU \), with block probability
                    matrix form, gives a column which is \( \rho_j \) in
                    the entries corresponding to \( E_j \) and \( 0 \)
                    elsewhere.
                \item
                    Therefore the columns form a fixed vector for \( W_j
                    \), this proves \( VUPV = PV \).
            \end{enumerate}
        \item
            \( (\Leftarrow) \)
            \begin{enumerate}
                \item
                    Assume \( VUPV = PV \).  Then the columns of \( PV \)
                    are fixed vectors for \( VU \).
                \item
                    But each block \( W_j \) is the transition
                    probability matrix, so its only fixed column vectors
                    are of the form \( c \mathbf{1} \).
                \item
                    Hence all the components of a column of \( PV \)
                    corresponding to a set \( E_i \) must be the same,
                    so the chain is lumpable.
            \end{enumerate}
    \end{enumerate}
\end{proof}

\begin{example}
    For the weather example with the ordering of states as \( N, R, S \)
    to correspond to \( \set{G,B} = \set{\set{N}, \set{R,S}} \),
    \[
        VU =
        \begin{pmatrix}
            1 & 0 \\
            0 & 1 \\
            0 & 1
        \end{pmatrix}
        \begin{pmatrix}
            1 & 0 & 0 \\
            0 & 1/2 & 1/2
        \end{pmatrix}
        =
        \begin{pmatrix}
            1 & 0 & 0 \\
            0 & 1/2 & 1/2 \\
            0 & 1/2 & 1/2
        \end{pmatrix}
        .
    \] Also
    \[
        PV =
        \begin{pmatrix}
            0 & 1/2 & 1/2 \\
            1/4 & 1/2 & 1/4 \\
            1/4 & 1/4 & 1/2
        \end{pmatrix}
        \begin{pmatrix}
            1 & 0 \\
            0 & 1 \\
            0 & 1
        \end{pmatrix}
        =
        \begin{pmatrix}
            0 & 1 \\
            1/4 & 3/4 \\
            1/4 & 3/4
        \end{pmatrix}
    \] and it is quick to check that \( VUPV = PV \).
\end{example}
\begin{corollary}
    \[
        \hat{P}^n = U P^n V.
    \]
\end{corollary}

\begin{proof}
    From the theorem,
    \[
        \hat{P}^2 = U P V U P V = U P^2 V
    \] and the corollary follows by induction.
\end{proof}

\subsection*{Lumping Absorbing Chains}

Assume \( P \) is an absorbing chain.  Restrict attention to the case of
lumping only states of the same kind.  That is, any subset of the
partition will contain only absorbing states or only nonabsorbing
states.  Recall that the standard form for an absorbing chain is
\[
    P =
    \begin{pmatrix}
        I & 0 \\
        R & Q
    \end{pmatrix}
\] and write \( U \) in the form
\[
    U =
    \begin{pmatrix}
        U_1 & 0 \\
        0 & U_{2}
    \end{pmatrix}
\] where entries of \( U_1 \) refer to absorbing states and entries of \(
U_2 \) to nonabsorbing states.  Similarly write \( V \) in the form
\[
    V =
    \begin{pmatrix}
        V_1 & 0 \\
        0 & V_{2}
    \end{pmatrix}
    .
\] In terms of this decomposition, the matrix condition for lumpability
becomes
\begin{align*}
    V_1 U_1 V_1 &= V_1 \\
    V_2 U_2 R V_1 &= R V_1 \\
    V_2 U_2 Q V_2 &= Q V_2.
\end{align*}
Since \( U_1 V_1 = I \), the first condition is automatically satisfied.
The standard form for the transition matrix \( \hat{P} \) is
\[
    \hat{P} = UPV =
    \begin{pmatrix}
        U_1 & 0 \\
        0 & U_{2}
    \end{pmatrix}
    \begin{pmatrix}
        I & 0 \\
        R & Q
    \end{pmatrix}
    \begin{pmatrix}
        V_1 & 0 \\
        0 & V_{2}
    \end{pmatrix}
    =
    \begin{pmatrix}
        I & 0 \\
        U_2 R V_1 & U_2 Q V_2
    \end{pmatrix}
    .
\] Then
\begin{align*}
    \hat{R} &= U_2 R V_1 \\
    \hat{Q} &= U_2 Q V_2.
\end{align*}
From \( V_2 U_2 Q V_2 = Q V_2 \), obtain \( \hat{Q}^2 = U_2 Q V_2 U_2 Q
V_2 = U_2 Q^2 V_2 \) and so on inductively.

From the infinite series representation for the fundamental matrix \( N \)
\begin{align*}
    \hat{N} &= I + \hat{Q} + \hat{Q}^2 + \cdots \\
    &= U_2 I V_2+ U_2 Q V_2 + U_2 Q^2 V_2 + \cdots \\
    &= U_2 (I + Q + Q^2 + \cdots) V_2 \\
    &= U_2 N V_2.
\end{align*}
From this \( \hat{\tau} = \hat{N} \mathbf{1} = U_2 N V_2 \mathbf{1} = U_2
N \mathbf{1} = U_2 \tau \) and
\begin{align*}
    \hat{B} = \hat{N} \hat{R} &= U_2 N V_2 U_2 R V_1 \\
    &= U_2 N R V_1 \\
    &= U_2 B V_1.
\end{align*}
So the important absorption quantities are all easily obtained for the
lumped chain from the original chain.

A consequence of \( \hat{\tau} = U_2 \tau \) is the following.  Let \( E_j
\) be any nonabsorbing set, and let \( x_i \) be a state in \( E_j \).
Choose the \( i \)th row of \( U_2 \) to be a probability vector with \(
1 \) in the \( x_i \) component.  This means for all \( x_\ell \) in \(
E_j \), \( \tau_\ell = \tau_i \).  When a chain is lumpable, the mean
time to absorption is the same for all starting states in the
equivalence set \( E_j \)

\subsection*{Lumping Ergodic Chains}

Assume the ergodic chain \( X \) with limiting matrix \( \Pi \) is
lumpable for some partition \( \hat{S} \). The resulting lumped chain
will be also be ergodic.  Let \( \hat{\Pi} \) be the limiting matrix for
the lumped chain.  Then
\begin{align*}
    \hat{\Pi} &= \lim_{\nu \to \infty} \frac{\hat{P} + \hat{P}^2 +
    \cdots + \hat{P}^{\nu}}{\nu} \\
    &= \lim_{\nu \to \infty} \frac{UPV + UP^2V + \cdots + UP^{\nu}V}{\nu}
    \\
    &= U \left( \lim_{\nu \to \infty} \frac{P + P^2 + \cdots + P^{\nu}}{\nu}
    \right) V \\
    & = U \Pi V.
\end{align*}
This states that the components of \( \hat{\pi} \) are obtained from \(
\pi \) by simply adding the components of a given set.  From the
infinite series representation for the fundamental matrix \( \hat{N} \)
\[
    \hat{N} = U N V.
\]

\subsection*{Larger Examples}

\begin{example}
    Consider a random walk%
    \index{random walk}
    of a particle moving along a straight line in unit steps.  Each step
    is \( 1 \) unit to the right with probability \( \frac{1}{2} \) and
    to the left with probability \( \frac{1}{2} \).  The particle moves
    until it reaches one of two extreme points which are absorbing
    boundaries.~%
    \index{absorption probability matrix}
    In particular, consider the small case where the state space has \(
    5 \) values with absorbing boundary states \( x_1 \) and \( x_5 \)
    and using the ordering for the standard form the probability
    transition matrix is
    \[
        P = \bordermatrix{ & s_1 & s_5 & s_2 & s_3 & s_4 \cr
        s_1 & 1 & 0 & 0 & 0 & 0 \cr
        s_5 & 0 & 1 & 0 & 0 & 0 \cr
        s_2 & 1/2 & 0 & 0 &1/2 & 0 \cr
        s_3 & 0 & 0 & 1/2 & 0 & 1/2 \cr
        s_4 & 0 & 1/2 & 0 & 1/2 & 0 \cr
        }.
    \] Take the partition \( S = \set{ \set{s_1, s_5}, \set{s_2, s_4},
    \set{s_3}} \).  For this partition the condition for lumpability is
    satisfied, see the exercises.  Notice that this would not have been
    the case for unequal probabilities of moving to left or right.

    It is easy to verify that (see the exercises)
    \begin{align*}
        \hat{P} &=
        \begin{pmatrix}
            1 & 0 & 0 \\
            1/2 & 0 & 1/2 \\
            0 & 1 & 0
        \end{pmatrix}
        , \\
        \hat{N} &=
        \begin{pmatrix}
            2 & 1 \\
            2 & 2
        \end{pmatrix}
        , \\
        \hat{\tau} &= (3, 4)^T \\
        \hat{B} &= (1,1)^T.
    \end{align*}
\end{example}

\begin{example}
    Let \( Q^k \) be the \( k \)-dimensional hypercube graph, with
    vertices or node set
    \[
        V(Q^k) = \set{x_0, x_1, \dots x_{2^k}} = \set{0,1}^k
    \] and edge set
    \[
        E(Q^k) = \setof{(x,y)}{x, y \text{ differ in one coordinate}}.
    \]%
    \index{hypercube}
    A lazy random walk on this graph is the sequence \( X_0, X_1, \dots,
    X_{n-1}, X_n, \dots \) where, given \( X_{n-1} \), first choose to
    remain at \( X_{n-1} \) with probability \( \frac{1}{2} \).
    Alternatively, with probability \( \frac{1}{2} \) choose to move to \(
    X_n \) selected uniformly at random from the nodes adjacent to \( x_
    {n-1} \).  A practical way to implement this random walk is to
    choose a coordinate \( j \in \set{1,2, \dots, k} \) uniformly at
    random and replace the bit in that position with the value of a fair
    Bernoulli random value.%
    \index{random walk!hypercube}
    \index{lazy random walk}
    \index{random walk!lazy}
    For example, on the \( 3 \)-dimensional cube a walk at \( 011 \)
    will move to \( 111 \) if coordinate \( 1 \) is selected, to \( 001 \)
    if coordinate \( 2 \) is selected, and \( 010 \) if coordinate \( 3 \)
    is selected.  As \( n \to \infty \), the distribution of \( X_n \)
    converges to the uniform distribution \( \pi = \frac{1}{2^k}\mathbf{1}
    \) on \( V(Q^k) \).  See the exercises.  The aperiodic lazy random
    walk avoids the annoying issue of the usual random walk being
    periodic with period \( 2 \).

    Two urns labeled \( A \) and \( B \) contain a total of \( k \)
    balls.  In the alternate Ehrenfest urn model a%
    \index{alternate Ehrenfest urn model}
    \index{Markov chain!alternate Ehrenfest urn model}
    \index{urn model}
    ball is selected at random with all selections equally likely, and
    moved from the urn it is in to the other urn.  The state at each
    time is the number of balls in the urn \( A \), from \( 0 \) to \( n
    \).  Then the transition probability matrix is
    \[
        P =
        \begin{pmatrix}
            0 & 1 & 0 & 0 & \cdots & 0 & 0 \\
            \frac{1}{2k} & \frac{1}{2} & \frac{1}{2}-\frac{1}{2k} & 0 &
            \cdots & 0 & 0 \\
            0 & \frac{2}{2k} & \frac{1}{2} & \frac{1}{2}-\frac{2}{k} &
            \cdots & 0 & 0 \\
            \vdots & \vdots & \vdots & \vdots & \ddots& \vdots & \vdots
            \\
            0 & 0 & 0 & 0 & \cdots & 0 & \frac{1}{2k} \\
            0 & 0 & 0 & 0 & \cdots & 1 & 0 \\
        \end{pmatrix}
        .
    \] The balls fluctuate between the two containers with generally a
    drift from the one with the larger number of balls to the one with
    the smaller numbers.

    The stationary distribution for this Markov chain has entry \( \pi_i
    = \binom{k}{i}/2^k \).  (See the exercises.) This is the binomial
    distribution on \( k \) with \( p = 1/2 \).  For large \( k \), the
    normal distribution approximates the stationary distribution.

    The alternate Ehrenfest urn model is a lumping of the lazy random
    walk on the \( k \)-dimensional hypercube.  A set \( E_{\nu} \) in
    the partition, that is, the equivalence class, is defined as the set
    of vertices with the sum of the coordinates equal to \( \nu \in \set
    {0,1,\dots, k} \).  The position of the lazy random walk on the
    hypercube specifies the set of balls in urn \( A \); changing a bit
    corresponds to moving that particular ball into or out of the urn.
    See the exercises to prove this using the lumping condition theorem.

\end{example}

\subsection*{Covariance}

It is possible to compute the covariance matrix of the lumped process.
The covariances are easily obtainable from \( C \) even if the original
process is not lumpable with respect to the partition, that is, the
lumped process is not a Markov chain.  In any case, the elements of the
covariance matrix \( \hat{C} \) for the lumped process are
\[
    \hat{c}_{ij} = \sum_{x_k \in E_i, x_{\ell} \in E_j } c_{k \ell}.
\]

\begin{example}
    For the weather in the Land of Oz example.
    \begin{align*}
        \hat{\Pi} &=
        \begin{pmatrix}
            0 & 1 & 0 \\
            1/2 & 0 & 1/2
        \end{pmatrix}
        ,
        \begin{pmatrix}
            2/5 & 1/5 & 2/5 \\
            2/5 & 1/5 & 2/5 \\
            2/5 & 1/5 & 2/5 \\
        \end{pmatrix}
        ,
        \begin{pmatrix}
            0 & 1 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix}
        , \\
        & =
        \begin{pmatrix}
            1/5 & 4/5 \\
            1/5 & 4/5
        \end{pmatrix}
        .
    \end{align*}
    \begin{align*}
        Z &=
        \begin{pmatrix}
            0 & 1 & 0 \\
            1/2 & 0 & 1/2
        \end{pmatrix}
        ,
        \begin{pmatrix}
            86/75 & 13/75 & -14/75 \\
            6/75 & 63/75 & 6/75 \\
            -14/75 & 3/75 & 86/75 \\
        \end{pmatrix}
        ,
        \begin{pmatrix}
            0 & 1 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix}
        \\
        & =
        \begin{pmatrix}
            63/75 & 12/75 \\
            3/75 & 72/75
        \end{pmatrix}
    \end{align*}
    \begin{align*}
        \hat{C} =
        \begin{pmatrix}
            12/125 & -12/125 \\
            -12/125 & 12/125
        \end{pmatrix}
        \\
        M &= \bordermatrix{ & R & N & S \cr
        R & 5/2 & 4 & 10/3 \cr
        N & 8/3 & 5 & 8/3 \cr
        S & 10/3 & 4 & 5/2}.
    \end{align*}
    From the fundamental matrix \( \hat{Z} \) find that
    \[
        \hat{M} = \bordermatrix{ & G & B \cr
        G & 5 & 1 \cr
        B & 4 & 5/4 }.
    \] The mean time to reach \( N \) from either \( R \) or \( S \) is \(
    4 \).  Recall that \( N \) in the lumped process is a single element
    set.  This common value is the mean time in the lumped chain to go
    from \( B \) to \( G \).  Similarly, the value \( 5 \) is obtainable
    from \( M \).  The mean time to go from \( G \) to \( B \) is less
    than the mean time to go from \( N \) to either of the states \( R,S
    \) in the original process.
\end{example}

\subsection*{Bounding Lumping Errors}

Starting from a distribution \( x_0 \) on \( \mathcal{X} \), the time
evolution among the lumped states \( E_j \) is \( \hat{x}_{t} = x_0 P^t
V \), while the time evolution of the lumped Markov chain is \( y_t = x_0V
\hat{P}^t \).  The question is how different these two dynamics can be.

For the following definition, \( \pi \) may be any properly sized
vector, but later it will be chosen to be the stationary distribution
vector. Define the norm \( \| \cdot \|_{\pi} \) by
\[
    \| v\|_{\pi} = \| v D_{\sqrt{\pi}} \|_2 = \sqrt{\sum_{\nu} v_{\nu}^2/\pi_\nu}
\] where \( D_{\sqrt{\pi}} =
\operatorname{diag}
(1/\sqrt{\pi_1}, \dots, 1/\sqrt{\pi_k}) \) and \( \| \cdot \|_2 \) is
the standard Euclidean \( 2 \)-norm.  The corresponding operator norm is
\begin{multline*}
    \| A \|_{\pi} = \max_{\|x\|_{\pi}=1}\|xA\|_{\pi} = \max_{\|xD_{\sqrt
    {\pi}}\|_2 = 1}\|x D_{\sqrt{\pi}} D_{\sqrt{\pi}}^{-1} A D_{\sqrt{\pi}}\|_
    {2} = \\
    \max_{\|w\|_2 = 1}\|w D_{\sqrt{\pi}}^{-1} A D_{\sqrt{\pi}}\|_{2} =
    \| D_{\sqrt{\pi}}^{-1} A D_{\sqrt{\pi}} \|_{2}.
\end{multline*}

Now using the \( v \)-dimensional stationary distribution vector \( \hat
{\pi} \) on the lumped chain, the one step time difference is
\[
    \| x_0 V \hat{P} - x_0 P V \|_{\hat{\pi}} = \| x_0 V U P V - x_0 P V
    \|_{\hat{\pi}} = \| x_0 (VUP - P) V \|_{\hat{\pi}}.
\] The \( n \) step time difference is
\begin{multline*}
    \| x_0 V \hat{P}^n - x_0 P^n V \|_{\hat{\pi}} = \| x_0 V (U P V)^n -
    x_0 P^n V \|_{\hat{\pi}} \\
    = \| x_0 V\,UPV\,UPV \cdots UPV\,UPV - x_0 P^n V \|_{\hat{\pi}} = \\
    \| x_0 (VUP)^{n}V - x_0 P^n V \|_{\hat{\pi}} = \| x_0 ((VUP)^n - P^n)
    V \|_ {\hat{\pi}}.
\end{multline*}
The important operator for bounding the difference is \( VUP \).  For
convenience, let \( VUP = H \).

The goal is to bound the \( n \)-step difference \( \| H^n - P^n \|_{\pi}
\) in terms of the \( 1 \)-step difference \( \| H - P\|_{\pi} \) now
using the right sized \( \pi \).  The general behavior of the difference
is that it can at most grow for a while, but must eventually decline to \(
0 \) since by construction the lumped and unlumped chain converge to the
same equilibrium distribution.  Bounding how large the difference can
get in terms of the \( 1 \)-step difference is the next theorem.

\begin{theorem}
    \label{thm:lumpedchains:normdifference} Assume \( P \) is the
    transition probability matrix for a regular and reversible Markov
    chain.  Let \( \delta = \| VUP - P \|_{\pi} \). Then
    \[
        \| (VUP)^n - P^n \|_{\pi} \le K(n) \delta \le \hat{K} \delta
    \] with \( K(n) = n \abs{\lambda_2}^{n-1} \), where \( \lambda_2 \)
    is the second largest eigenvalue of \( P \) and \( \hat{K} = -1/(\lambda_2
    \cdot \EulerE \cdot \log(\lambda_2)) \).
\end{theorem}

\begin{remark}
    For further understanding, the matrices and projections used in the
    following proof are illustrated in the small case of the lumped
    weather example after the proof.
\end{remark}

\begin{proof}
    \begin{enumerate}
        \item
            First note that
            \[
                \| H^n - P^n \|_{\pi} = \|(H-P)H^{n-1}+P(H^{n-1} -P^{n-1})\|_
                {\pi}.
            \]
        \item
            Iterating,
            \begin{align*}
                \| H^n - P^n \|_{\pi} &= \| \sum_{\nu=0}^{n-1} P^\nu(H-P)H^
                {n-\nu-1}\|_{\pi} \\
                & \le \sum_{\nu=0}^{n-1} \| P^\nu(H-P)H^{n-\nu-1}\|_{\pi}.
            \end{align*}
        \item
            Recall that \( H \) and \( P \) have common stationary
            distribution \( \pi \).  Define the projection \( P_{\pi} =
            \mathbf{1} \pi \) where \( \mathbf{1} \) is an \( k \times 1
            \) column vector and \( \pi \) is a \( 1 \times k \) row
            vector.  \( P_{\pi} \) projects a column vector into the \(
            1 \)-dimensional subspace spanned by \( \mathbf{1} \).
        \item
            The complementary projection is \( P_{\Sigma} = I - P_{\pi} \).
            % \( P_{\Sigma} \) projects any vector onto the
            % orthogonal subspace \( \Sigma = \setof{v}{v^{T} \mathbf{1} = 0} \) which is
            % invariant under the action of any stochastic matrix.
        \item
            The decomposition into the subspaces gives the following
            representations of \( P \) and \( H \):
            \begin{align*}
                P &= (P_{\pi} + P_{\Sigma}) P = P_{\pi} + P_{\Sigma}P \\
                H &= (P_{\pi} + P_{\Sigma}) H = P_{\pi} + P_{\Sigma}H \\
            \end{align*}
            because \( P_{\pi}P = P_{\pi} \) and \( P_{\pi}H = P_{\pi} \)
            since the rows of \( P_{\pi} \) are the stationary vector \(
            \pi \).
        \item
            Then \( H - P = P_{\Sigma}H - P_{\Sigma}P \) and \( 0 = P_{\pi}
            P_{\Sigma} P = P_{\Sigma} P P_{\pi} = P_{\pi} P_{\Sigma} H =
            P_{\Sigma} H P_{\pi} \).
        \item
            Recall \( \delta = \| VUP - P \|_{\pi} \) and \( VUP = H \),
            so \( \| VUP - P \|_{\pi} = \| H - P \|_{\pi} = \|P_{\Sigma}H
            - P_{\Sigma}P\|_{\pi} = \delta \).
        \item
            For integers \( \nu \), \( n \)
            \begin{align*}
                & \| P^\nu(H-P)H^{n-\nu-1} \|_{\pi} \\
                & \qquad = \|(P_{\pi}+P_{\Sigma}P)^\nu(P_{\Sigma}H-P_{\Sigma}P)
                (P_{\pi}+P_{\Sigma}H)^{n-1-\nu}\|_{\pi} \\
                & \qquad = \|(P_{\Sigma}P)^\nu(P_{\Sigma}H-P_{\Sigma}P)
                (P_ {\Sigma}H)^{n-1-\nu}\|_{\pi} \\
                & \qquad = \| P_{\Sigma} P \|_{\pi}^\nu \cdot \delta
                \cdot \|P_{\Sigma}H\|_ {\pi}^{n-\nu-1}.
            \end{align*}
        \item
            Use the special choice of norm, in particular, use the fact
            that for a matrix \( \| A \|_{\pi} = \| D_{\sqrt{\pi}}^{-1}
            A D_{\sqrt{\pi}} \|_{2} \).  By the assumption of
            reversibility, \( D_{\sqrt{\pi}}^{-1} P D_{\sqrt{\pi}} \) is
            a symmetric matrix.  Therefore, the \( 2 \)-norm is the
            dominant eigenvalue of the matrix.  In fact, as shown below
            the diagonal matrix \( D_{\sqrt{\pi}} \) also symmetrizes \(
            P_{\pi} \) (see step~%
            \ref{item:lumpedchains:stepnine}), \( P_{\pi}P \), (see
            step~%
            \ref{item:lumpedchains:stepten}), \( P_{\Sigma}P \) (see
            step~%
            \ref{item:lumpedchains:stepeleven}), and \( VU \) (see
            steps~%
            \ref{item:lumpedchains:steptwelve} and~%
            \ref{item:lumpedchains:stepthirteen}). Therefore each has
            norm equaling the dominant eigenvalue.
        \item
            \label{item:lumpedchains:stepnine} Direct calculation shows \(
            \pi D_{\sqrt{\pi}} = \mathbf{1}^T D_{\sqrt{\pi}}^{-1} \).
            Starting with the definition of \( P_{\pi} \)
            \begin{multline*}
                D_{\sqrt{\pi}}^{-1} P_{\pi} D_{\sqrt{\pi}} = D_{\sqrt{\pi}}^
                {-1}\mathbf{1} \pi D_{\sqrt{\pi}} = (\mathbf{1}^T D_{\sqrt
                {\pi}}^{-1})^T(\pi D_{\sqrt{\pi}}) = \\
                (\pi D_{\sqrt{\pi}})^T(\pi D_{\sqrt{\pi}})^T = ( (\pi D_
                {\sqrt{\pi}})^T(\pi D_{\sqrt{\pi}}))^T = ( (\mathbf{1}^T
                D_{\sqrt{\pi}}^{-1})^T (\pi D_{\sqrt{\pi}}))\\
                = ( (D_{\sqrt{\pi}}^{-1} \mathbf{1}) (\pi D_{\sqrt{\pi}}))^T
                = ( D_{\sqrt{\pi}}^{-1} (\mathbf{1} \pi ) D_{\sqrt{\pi}})^T
                = (D_{\sqrt{\pi}}^{-1} P_{\pi} D_{\sqrt{\pi}})^T.
            \end{multline*}
            This shows \( P_{\pi} \) is symmetrized by \( D_{\sqrt{\pi}}
            \).
        \item
            \label{item:lumpedchains:stepten} So \( D_{\sqrt{\pi}}^{-1}
            P D_{\sqrt{\pi}} \) and \( D_{\sqrt{\pi}}^{-1} P_{\pi} D_{\sqrt
            {\pi}} \) are symmetric and commute with each other since \(
            P \) and \( P_{\pi} \) commute.  Thus, \( D_{\sqrt{\pi}}^{-1}
            P_{\pi} P D_{\sqrt{\pi}} = D_{\sqrt{\pi}}^{-1} P_{\pi} D_{\sqrt
            {\pi}} D_{\sqrt{\pi}}^{-1} P D_{\sqrt{\pi}} \) is symmetric.
        \item
            \label{item:lumpedchains:stepeleven} Then \( D_{\sqrt{\pi}}^
            {-1} P_{\Sigma} P D_{\sqrt{\pi}} = D_{\sqrt{\pi}}^{-1} (I-P_
            {\pi}) P D_{\sqrt{\pi}} \) is symmetric as well.
        \item
            \label{item:lumpedchains:steptwelve} From \( U_{ij} = V_{ji}
            \frac{\pi_j}{\hat{\pi}_{i}} \), it follows that \( U = D_{\hat
            {\pi}}^2 V^T D_{\sqrt{\pi}}^{-2} \) or equivalently \( D_{\hat
            {\pi}}^{-1} U D_{\sqrt{\pi}} = D_{\hat{\pi}} V^T D_{\sqrt{\pi}}^
            {-1} \).
        \item
            \label{item:lumpedchains:stepthirteen} Thus,
            \begin{align*}
                D_{\sqrt{\pi}}^{-1} VU D_{\sqrt{\pi}} &= (D_{\sqrt{\pi}}^
                {-1} V D_{\hat{\pi}}) (D_{\hat{\pi}}^{-1} U D_{\sqrt{\pi}})
                \\
                &= (D_{\sqrt{\pi}}^{-1} V D_{\hat{\pi}})(D_{\hat{\pi}}^{-1}
                V^T D_{\sqrt{\pi}}^{-1}) \\
                &= (D_{\sqrt{\pi}}^{-1} V D_{\hat{\pi}})(D_{\sqrt{\pi}}^
                {-1} V D_{\hat{\pi}})^T.
            \end{align*}
            As the product of a matrix and its transpose, \( VU \) is
            symmetrized by \( D_{\sqrt{\pi}} \).
        \item
            Since \( D_{\sqrt{\pi}}^{-1} P_{\Sigma} P D_{\sqrt{\pi}} \)
            is symmetric and using the definition of the matrix norm, \(
            \| P_{\Sigma} P \|_{\pi} = \abs{\lambda_2} \), where \(
            \lambda_2 \) is the second-largest eigenvalue of \( P \).
            To bound \( \| P_ {\pi} H \|_{\pi} \):
            \begin{multline*}
                \| P_{\Sigma} H \|_{\pi} = \| VUP - P_{\pi} \|_{\pi} =
                \| VUP - VUP_{\pi}\|_{\pi} \\
                = \| VU(P - P_{\pi})\|_{\pi} \le \|P_{\Sigma} P\|_{\pi}
                \|VU\|_{\pi} = \abs{\lambda_2} \|VU\|_{\pi}.
            \end{multline*}
        \item
            Since \( VU \) is a stochastic matrix and\( D_{\sqrt{\pi}} \)
            symmetrizes \( VU \), it follows that \( \| VU \|_{\pi} = 1 \).
        \item
            Thus the bound becomes \( \| H^n - P^n\|_{\pi} \le n \abs{\lambda_2}^
            {n-1} \delta = K(n) \delta \) where \( K(n) = n \abs{\lambda_2}^
            {n-1} \).
        \item
            Maximizing \( K(n) \) over \( n \) gives \( K(n) \le \hat{K}
            = \frac{-1}{\lambda_2 \cdot \EulerE \cdot \log(\lambda_2)} \).
    \end{enumerate}
\end{proof}

\begin{corollary}
    \[
        \| x_0 V \hat{P}^n - x_0 P^n V \|_{\hat{\pi}} \le K_2 \cdot n
        \abs{\lambda_2}^2 \cdot \delta
    \] where \( \delta = \| VUP - P \|_{\pi} \), \( \lambda_2 \) is the
    second largest eigenvalue of \( P \) and \( K_2 \) is a constant
    related to \( x_0 \) and \( V \).
\end{corollary}

\begin{proof}
    See the exercises.
\end{proof}

\begin{example}
    For the weather example, the stationary distribution for \( P \) is \(
    (2/5, 1/5, 2/5) \) so the vector norm is
    \[
        \| v \| = \sqrt{\frac{5v_1^2}{2} + 5v_2^2 + \frac{5v_3^2}{2}}
    \] and the diagonalizing matrix is
    \[
        D_{\sqrt{\pi}} =
        \begin{pmatrix}
            1/\sqrt{5/2} & 0 & 0 \\
            0 & 1/\sqrt{1/5} & 0 \\
            0 & 0 & 1/\sqrt{5/2}
        \end{pmatrix}
        .
    \] The transition probability matrix and the collecting and
    distributing matrices are
    \[
        P =
        \begin{pmatrix}
            1/2 & 1/4 & 1/4 \\
            1/2 & 0 & 1/2 \\
            1/4 & 1/4 & 1/2
        \end{pmatrix}
        , \quad V =
        \begin{pmatrix}
            0 & 1 \\
            1 & 0 \\
            0 & 1
        \end{pmatrix}
        , \quad U =
        \begin{pmatrix}
            0 & 1 & 0 \\
            1/2 & 0 & 1/2
        \end{pmatrix}
    \] so
    \[
        H = VUP =
        \begin{pmatrix}
            3/8 & 1/4 & 3/8 \\
            1/2 & 0 & 1/2 \\
            3/8 & 1/4 & 3/8
        \end{pmatrix}
        .
    \] The eigenvalues of \( P \) are \( 1 \), \( 1/4 \), and \( -1/4 \).
    The stationary distribution for \( H \) is also \( (2/5, 1/5, 2/5) \)
    and the eigenvalues of \( H \) are \( 1 \), \( 0 \), and \( -1/4 \).

    The projections are
    \[
        P_{\pi} = \mathbf{1} \pi
        \begin{pmatrix}
            2/5 & 1/5 & 2/5 \\
            2/5 & 1/5 & 2/5 \\
            2/5 & 1/5 & 2/5 \\
        \end{pmatrix}
        \quad P_{\Sigma} = I - P_{\pi}
        \begin{pmatrix}
            3/5 & -1/5 & -2/5 \\
            -2/5 & 4/5 & -2/5 \\
            -2/5 & -1/5 & 3/5 \\
        \end{pmatrix}
        .
    \]

    Although it is obvious by construction, directly verifying
    \begin{align*}
        P &= (P_{\pi} + P_{\Sigma}) P = P_{\pi} + P_{\Sigma}P \\
        H &= (P_{\pi} + P_{\Sigma}) H = P_{\pi} + P_{\Sigma}H\\
    \end{align*}
    and \( H - P = P_{\Sigma}H - P_{\Sigma}P \) and \( 0 = P_{\pi} P_{\Sigma}
    P = P_{\Sigma} P P_{\pi} = P_{\pi} P_{\Sigma} H = P_{\Sigma} H P_{\pi}
    \) is easy. Although it is obvious by construction, it is also easy
    to verify that \( D_{\sqrt{\pi}}^{-1}P D_{\sqrt{\pi}} \) is
    symmetric directly by computation. The diagonal matrix \( D_{\sqrt{\pi}}
    \) also symmetrizes \( P_{\pi} \), \( P_{\pi}P \), \( P_{\Sigma}P \),
    and \( VU \).

    Figure~%
    \ref{{fig:lumpedchains:normdifference}} illustrates the numerical
    norm difference of the lumped chain from lumping the original chain
    with the blue points.  The upper bound from the eigenvalue is
    illustrated with the red points, showing that the inequality is
    satisfied.

    \begin{figure}
        \centering
        \includegraphics[scale=0.75]{normdifference}
        \caption{The numerical norm difference of the lumped chain from
        lumping the original chain in blue with the theoretical upper
        bound in red.}%
        \label{fig:lumpedchains:normdifference}
    \end{figure}
\end{example}

\visual{Section Starter Question}{../../../../CommonInformation/Lessons/question_mark.png}
\section*{Section Ending Answer}

The probability of going from \( R \) to either \( R \) or \( S \) is \(
\frac{1}{4} + \frac{1}{2} = \frac{3}{4} \).  The probability of going
from \( S \) to either \( R \) or \( S \) is \( \frac{1}{2} + \frac{1}{4}
= \frac{3}{4} \).  Any probability combination of being in the states \(
R \) and \( S \) leads to a probability \( \frac{3}{4} \) of being in
the states \( R \) or \( S \), so the probability of going from bad
weather to bad weather is \( \frac{3}{4} \).

\subsection*{Sources} The example of reducing the PageRank matrix is
from \link{https://www.cs.mcgill.ca/~amsb/files/sf_mc_conf.pdf} {Barreto
and Fragoso}.

The example of lumped chains from clustering or ``communities'' and the
diagram are adapted from \link{https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3207820/}
{Piccardi}.

The example of a lumped chain which is not Markov is adapted from class
notes from \link{http://www.math.umd.edu/~slud/s650/NonMarkov.pdf}{Eric
Slud, Statistics 650}.

The accuracy bounds on the lumped chain are adapted from
\cite{HOFFMANN20091471}

The example of lumping a random walk on the hypercube to the Ehrenfest
urn model is based on Sections 2.3 of
\cite{levin09}.

\nocite{}
\nocite{}

\hr

\visual{Algorithms, Scripts, Simulations}{../../../../CommonInformation/Lessons/computer.png}
\section*{Algorithms, Scripts, Simulations}

\subsection*{Algorithm}
\begin{algorithm}[H]
  \DontPrintSemicolon
  \KwData{Transition probability matrix, collecting, distributing,
    diagonal matrices}
  \KwResult{Plot of norm difference between lumped and original chain}
  \BlankLine
  \emph{Initialization of Matrices}\;
  Initialize \( P \), \( V \), \( U \), \( D \), \(Dinv \)\;
  Initialize \( \lambda_2 \)\;
  Initialize number of iterations \( N \)\;
  \( H \leftarrow VUP \)\;
  \( H_n \leftarrow H \)\;
  \( P_n \leftarrow P \)\;
  \BlankLine
  \( normDifference \leftarrow [ \| Dinv (H_n - P_n) D \|_2 ]\)\;
  \For{\( n \leftarrow 1 \) \KwTo \( N-1 \)}{
      \( H_n \leftarrow H H_n \)\;
      \( P_n \leftarrow P P_n \)\;
      Append \( \| Dinv (H_n - P_n) D \|_2 \) to \( normDifference \)\;
    }
  Generate comparison list \( n \lambda_2^{n-1} \) for \(n = 1:N \)\;
  Plot \( normDifference \) and comparison list on same axes\;
  \caption{Illustration of Theorem~\ref{thm:lumpedchains:normdifference}.}
\end{algorithm}
\subsection*{Scripts}

\input{lumpedchains_scripts}

\hr

\visual{Problems to Work}{../../../../CommonInformation/Lessons/solveproblems.png}
\section*{Problems to Work for Understanding}
\renewcommand{\theexerciseseries}{}
\renewcommand{\theexercise}{\arabic{exercise}}

\begin{exercise}
    For the \( 5 \)-state absorbing random walk with transition
    probability matrix
    \[
        P = \bordermatrix{ & s_1 & s_5 & s_2 & s_3 & s4 \cr
        s_1 & 1 & 0 & 0 & 0 & 0 \cr
        s_5 & 0 & 1 & 0 & 0 & 0 \cr
        s_2 & 1/2 & 0 & 0 &1/2 & 0 \cr
        s_3 & 0 & 0 & 1/2 & 0 & 1/2 \cr
        s_4 & 0 & 1/2 & 1/2 & 0 & 0 \cr
        }
    \] and partition \( S = \set{ \set{s_1, s_5}, \set{s_2, s_4}, \set{s_3}}
    \) show that the condition for lumpability is satisfied. Verify that
    \begin{align*}
        \hat{P} &=
        \begin{pmatrix}
            1 & 0 & 0 \\
            1/2 & 0 & 1/2 \\
            0 & 1 & 0
        \end{pmatrix}
        \\
        \hat{N} &=
        \begin{pmatrix}
            2 & 1 \\
            2 & 2
        \end{pmatrix}
        \\
        \hat{\tau} &= (3, 4)^T \\
        \hat{B} &= (1,1)^T.
    \end{align*}
\end{exercise}
\begin{solution}
    To conform to the theorem, reorder the states to \( s_1, s_5, s_2, s_4,
    s_3 \) so
    \[
        P =
        \begin{pmatrix}
            1 & 0 & 0 & 0 & 0\\
            0 & 1 & 0 & 0 & 0\\
            1/2 & 0 & 0 & 0 & 1/2\\
            0 & 1/2 & 0 & 0 & 1/2\\
            0 & 0 & 1/2 & 1/2 & 0
        \end{pmatrix}
        .
    \]

    Since this is an absorbing, not an ergodic, chain, applying the
    observation that all that is needed for \( U \) is that the \( i \)th
    row should be a probability vector with nonzero components only for
    states in \( E_i \)
    \[
        U =
        \begin{pmatrix}
            1/2 & 1/2 & 0 & 0 & 0 \\
            0 & 0 & 1/2 & 1/2 & 0 \\
            0 & 0 & 0 & 0 & 1
        \end{pmatrix}
    \] and
    \[
        V =
        \begin{pmatrix}
            1 & 0 & 0 \\
            1 & 0 & 0 \\
            0 & 1 & 0 \\
            0 & 1 & 0 \\
            0 & 0 & 1
        \end{pmatrix}
        .
    \] Then
    \[
        VUPV = PV =
        \begin{pmatrix}
            1 & 0 & 0 \\
            1 & 0 & 0 \\
            1/2 & 0 & 1/2 \\
            1/2 & 0 & 1/2 \\
            0 & 1 0
        \end{pmatrix}
    \] so the absorbing random walk is lumpable.

    First calculate all the quantities for the original random walk.
    \begin{align*}
        R &=
        \begin{pmatrix}
            1/2 & 0 \\
            0 & 1/2 \\
            0 & 0
        \end{pmatrix}
        \\
        Q &=
        \begin{pmatrix}
            0 & 0 & 1/2 \\
            0 & 0 & 1/2 \\
            1/2 & 1/2 & 0
        \end{pmatrix}
        \\
        N &= (I_3 - Q)^{-1} =
        \begin{pmatrix}
            3/2 & 1/2 & 1 \\
            1/2 & 3/2 & 1 \\
            1 & 1 & 2
        \end{pmatrix}
        \\
        \tau & = N \mathbf{1} = (3, 3, 4)^T \\
        B &= NR =
        \begin{pmatrix}
            3/4 & 1/4 \\
            1/4 & 3/4 \\
            1/2 & 1/2
        \end{pmatrix}
        .
    \end{align*}

    Next calculate the absorption quantities for the lumped chain from
    the original chain using the submatrices \( U_1, U_2, V_1, V_2 \) of
    \( U, V \).
    \begin{align*}
        \hat{P} &=
        \begin{pmatrix}
            1 & 0 & 0 \\
            1/2 & 0 & 1/2 \\
            0 & 1 & 0
        \end{pmatrix}
        , \\
        \hat{N} &= U_2 N V_2 =
        \begin{pmatrix}
            2 & 1 \\
            2 & 2
        \end{pmatrix}
        , \\
        \hat{\tau} & \hat{N} \mathbf{1} = (3,4)^T, \\
        \hat{B} &= U_2 B V_1 = (1,1)^T.
    \end{align*}

    Finally calculate the absorption quantities from the lumped chain
    canonical \( \hat{P} \) directly.
    \begin{align*}
        \hat{Q} &=
        \begin{pmatrix}
            0 & 1/2 \\
            1 & 0
        \end{pmatrix}
        , \hat{R} &= (1/2, 0)^T, \\
        \hat{N} &= (I_2 - \hat{Q})^{-1} =
        \begin{pmatrix}
            2 & 1 \\
            2 & 2
        \end{pmatrix}
        , \\
        \hat{\tau} &= \hat{N} \mathbf{1} = (3,4)^T, \\
        \hat{B} &= \hat{N} \hat{R} = (1,1)^T.
    \end{align*}

    Both calculations of the absorption quantities agree.
\end{solution}

\begin{exercise}
    Show that for irreducible and aperiodic chains with \( \hat{\pi} =
    \pi V \)
    \[
        U_{ij} = V_{ji} \frac{\pi_j}{\hat{\pi}_{i}}, \quad i = 1, \dots,
        k, j = 1, \dots, v
    \] whose \( i \)th row, \( i = 1, 2, \dots, v \), is the probability
    vector having equal values for states in \( E_{\xi} \) and \( 0 \)
    elsewhere.
\end{exercise}
\begin{solution}
    On the left side
    \[
        U_{ij} =
        \begin{cases}
            \pi_j/\sum_{x_{\nu} \in E_i} \pi_\nu & x_j \in E_i \\
            0 & \text{otherwise}.
        \end{cases}
    \] On the right side, because \( \hat{\pi} = \pi V \), \( \hat{\pi}_i
    = \sum_{x_{\nu} \in E_i} \pi_{\nu} \).  Additionally, \( V_{ji} = 1 \)
    if \( x_j \in E_i \) and \( 0 \) otherwise.  Then the terms on the
    right side correspond precisely to the terms on the left side.
\end{solution}

\begin{exercise}
    For the lazy random walk \( X_n \) on the hypercube \( Q^k \) show
    that as \( n \to \infty \), the distribution of \( X_n \) converges
    to the uniform distribution \( \pi \) on \( V(Q^k) \).
\end{exercise}
\begin{solution}
    As a weighted random walk on a graph, the lazy random walk as a
    Markov chain is irreducible and reversible.  For a hypercube of
    dimension \( k \), the number of edges from each vertex is the
    dimension of the hypercube \( k \), and the total number of vertices
    is \( 2^k \).  The lazy random walk is associated with the weighted
    graph with self-edges with weight \( w_{ii} = k \) and \( k \) edges
    each with weight \( w_{ij} = 1 \).  The sum of all weights from the \(
    2^k \) nodes is
    \[
        s = \sum_{i,j} w_{ij} = (2k) \cdot 2^{k}.
    \] The section on Reversible Markov Chains shows the invariant
    distribution is
    \[
        \pi_i = = \frac{2k}{2 \cdot (2k) \cdot 2^n} = \frac{1}{2^n}.
    \]
\end{solution}

\begin{exercise}
    Prove that the stationary distribution for the alternate Ehrenfest
    urn model has entry \( \pi_i = \binom{k}{i}/2^k \).
\end{exercise}

\begin{solution}
    Entry \( i \) must satisfy
    \begin{multline*}
        \binom{k}{i-1}\left( \frac{1}{2} \right)^k \cdot \frac{k-i+1}{2k}
        + \binom{k}{i}\left( \frac{1}{2} \right)^k \cdot \frac{1}{2} +
        \binom{k}{i+1}\left( \frac{1}{2} \right)^k \cdot \frac{i+1}{k} =
        \\
        \binom{k}{i}\left( \frac{1}{2} \right)^k
    \end{multline*}
    or more simply
    \[
        \binom{k}{i-1} \cdot \frac{k-i+1}{2k} + \binom{k}{i} \cdot \frac
        {i}{2k} + \binom{k}{i+1} \cdot \frac{i+1}{2k} = \binom{k}{i}.
    \] This reduces to
    \[
        \binom{k-1}{i-1} + \binom{k-1}{i+1} = \binom{k}{i},
    \] the basic binomial (Pascal triangle) identity.
\end{solution}

\begin{exercise}
    Show the Ehrenfest urn model is a lumping of the random walk on the \(
    n \)-dimensional hypercube using the correspondence between \( \set{0,1}^n
    \) and subsets of \( \set{1, \dots, n} \), under which a vertex
    corresponds to the vector or bit string with \( 1 \)s in the
    positions of its elements.  The position of the random walk on the
    hypercube specifies the set of balls in urn \( A \); changing a bit
    corresponds to moving that numbered ball into or out of the urn.
\end{exercise}
\begin{solution}
    The lumpability criterion is that for every pair of sets \( E_{\xi} \)
    and \( E_{\eta} \), \( \sum_{x_{\nu} \in E_{\eta}} p_{i\nu} \) has
    the same value for every \( x_i \in E_{\xi} \).  These common values
    form the transition probabilities \( \hat{p}_{\xi,\eta} \) for the
    lumped chain.  If \( \xi \) and \( \eta \) differ by more than \( 1 \),
    then for every \( x_i \in E_{\xi} \), \( p_{i,\nu} = 0 \) for \( \nu
    \in E_{\eta} \), so \( \sum_{x_{\nu} \in E_{\eta}} p_{i\nu} = 0 \).
    If \( \xi - \eta = 1 \) then for every \( x_i \in E_{\xi} \), \( p_{i,\nu}
    = \frac{1}{n} \) and \( \sum_{x_{\nu} \in E_{\eta}} p_{i\nu} = \frac
    {\xi}{n} \).  If \( \xi - \eta = -1 \) then for every \( x_i \in E_
    {\xi} \), \( p_{i,\nu} = \frac{1}{n} \) and \( \sum_{x_{\nu} \in E_{\eta}}
    p_{i\nu} = \frac{n-\xi}{n} \).  This proves the lumpability
    criterion.
\end{solution}

\begin{exercise}
    For the lumping of the lazy random walk on the \( 3 \)-dimensional
    cube \( Q^3 \) starting at the origin, into the alternate Ehrenfest
    urn model with \( 3 \) balls, plot the norm-difference of the
    Ehrenfest urn model from the lumped random walk and compare to the
    theoretical upper bound.
\end{exercise}
\begin{solution}
    \[
        P = \bordermatrix{ & 000 & 100 & 010 & 001 & 101 & 011 & 110 &
        111 \cr
        000 & 1/2 & 1/6 & 1/6 & 1/6 & 0 & 0 & 0 & 0 \cr
        100 & 1/6 & 1/2 & 0 & 0 & 1/6 & 0 & 1/6 & 0 \cr
        010 & 1/6 & 0 & 1/2 & 0 & 0 & 1/6 & 1/6 & 0 \cr
        001 & 1/6 & 0 & 0 & 1/2 & 1/6 & 1/6 & 0 & 0 \cr
        101 & 0 & 1/6 & 0 & 1/6 & 1/2 & 0 & 0 & 1/6 \cr
        011 & 0 & 0 & 1/6 & 1/6 & 0 & 1/2 & 0 & 1/6 \cr
        110 & 0 & 1/6 & 1/6 & 0 & 0 & 0 & 1/2 & 1/6 \cr
        111 & 0 & 0 & 0 & 0 & 1/6 & 1/6 & 1/6 & 1/2 \cr
        }.
    \] The transition probability matrix is symmetric so the random walk
    Markov chain is reversible with stationary vector previously
    determined to be \( \pi = (1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8, 1/8) \).
    The eigenvalues of \( P \) are \( 1, 2/3, 1/3, 0 \) with
    multiplicities \( 1,3,3,1 \) respectively, so \( \lambda_2 = 2/3 \).

    The partition is \( \hat{S} = \set{E_0, E_1, E_2, E_3} = \set{ \set{000},
    \set{100, 010, 001}, \set{101, 011.  110}, \set{111}} \). The lumped
    transition probability matrix is
    \[
        \hat{P} = \bordermatrix{ & E_0 & E_1 & E_2 & E_3 \cr
        E_0 & 1/2 & 1/2 & 0 & 0 \cr
        E_1 & 1/6 & 1/2 & 2/6 & 0 \cr
        E_2 & 0 & 2/6 & 1/2 & 1/6 \cr
        E_3 & 0 & 0 & 1/2 & 1/2 \cr
        }
    \] with \( \hat{\pi} = (1/8, 3/8, 3/8, 1/8) \).

    \[
        U =
        \begin{pmatrix}
            1 & 0 & 0 & 0 & 0 & 0 & 0 & 0 \\
            0 & 1/3 & 1/3 & 1/3 & 0 & 0 & 0 & 0 \\
            0 & 0 & 0 & 0 & 1/3 & 1/3 & 1/3 & 0 \\
            0 & 0 & 0 & 0 & 0 & 0 & 0 & 1\\
        \end{pmatrix}
    \] and
    \[
        V =
        \begin{pmatrix}
            1 & 0 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 1 & 0 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 0 & 1 & 0 \\
            0 & 0 & 0 & 1 \\
        \end{pmatrix}
    \] and
    \[
        VUP =
        \begin{pmatrix}
            1/2 & 1/6 & 1/6 & 1/6 & 0 & 0 & 0 & 0\\
            1/6 & 1/6 & 1/6 & 1/6 & 1/9 & 1/9 & 1/9 & 0\\
            1/6 & 1/6 & 1/6 & 1/6 & 1/9 & 1/9 & 1/9 & 0\\
            1/6 & 1/6 & 1/6 & 1/6 & 1/9 & 1/9 & 1/9 & 0\\
            0 & 1/9 & 1/9 & 1/9 & 1/6 & 1/6 & 1/6 & 1/6\\
            0 & 1/9 & 1/9 & 1/9 & 1/6 & 1/6 & 1/6 & 1/6\\
            0 & 1/9 & 1/9 & 1/9 & 1/6 & 1/6 & 1/6 & 1/6\\
            0 & 0 & 0 & 0 & 1/6 & 1/6 & 1/6 & 1/2
        \end{pmatrix}
        .
    \]

    Because the stationary distribution is uniform, the \( \pi \)-norm
    is simply scaling the standard Euclidean norm by \( \sqrt{8} \).
    Then use the following R script.

    \begin{lstlisting}[language=R]
        # Enter matrices by rows, so use keyword byrow P <- matrix( c(1/2,
        1/6, 1/6, 1/6, 0, 0, 0, 0, 1/6, 1/2, 0, 0, 1/6, 0, 1/6, 0, 1/6,
        0, 1/2, 0, 0, 1/6, 1/6, 0, 1/6, 0, 0, 1/2, 1/6, 1/6, 0, 0, 0,
        1/6, 0, 1/6, 1/2, 0, 0, 1/6, 0, 0, 1/6, 1/6, 0, 1/2, 0, 1/6, 0,
        1/6, 1/6, 0, 0, 0, 1/2, 1/6, 0, 0, 0, 0, 1/6, 1/6, 1/6, 1/2),
        byrow=TRUE, nrow=8, ncol=8)

        V <- matrix( c(1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,
        0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1), byrow=TRUE,
        nrow=8, ncol=4)

        U <- matrix( c(1, 0, 0, 0, 0, 0, 0, 0, 0, 1/3, 1/3, 1/3, 0, 0,
        0, 0, 0, 0, 0, 0, 1/3, 1/3, 1/3, 0, 0, 0, 0, 0, 0, 0, 0, 1),
        byrow=TRUE, nrow=4, ncol=8)

        D <- diag(1/sqrt(8), nrow=8, ncol=8) Dinv <- diag(sqrt(8),
        nrow=8, ncol=8)

        lambda2 <- 2/3

        N <- 10 H <- V %*% U %*% P
        Hn <- H Pn <- P

        normdifference <- c( norm( Dinv %*% (Hn - Pn) %*% D, type="2") )
        for (n in 1:(N-1) ) { Hn <- H %*% Hn
        Pn <- P %*% Pn
        normdifference <- c( normdifference, norm( Dinv
        %*% (Hn - Pn) %*% D, type="2") )
        } plot(normdifference, col="blue")

        K <- function(n, l2) { n * l2^{n-1} } points(K(1:N, lambda2),
        col="red")
    \end{lstlisting}
\end{solution}

\begin{exercise}
    Show
    \[
        \| x_0 V \hat{P}^n - x_0 P^n V \|_{\hat{\pi}} \le K_2 \cdot n
        \abs{\lambda_2}^2 \cdot \delta
    \] where \( \delta = \| VUP - P \|_{\pi} \), \( \lambda_2 \) is the
    second largest eigenvalue of \( P \) and \( K_2 \) is a constant
    related to \( x_0 \) and \( V \).
\end{exercise}
\begin{solution}

\end{solution}
% \begin{exercise}
%     \begin{enumerate}[label=(\alpha*)]
%     \item
% \end{enumerate}
% \end{exercise}
% \begin{solution}
%     \begin{enumerate}[label=(\alpha*)]
%     \item
% \end{enumerate}
% \end{solution}

\hr

\visual{Books}{../../../../CommonInformation/Lessons/books.png}
\section*{Reading Suggestion:}

\bibliography{../../../../CommonInformation/bibliography}

%   \begin{enumerate}
%     \item
%     \item
%     \item
%   \end{enumerate}

\hr

\visual{Links}{../../../../CommonInformation/Lessons/chainlink.png}
\section*{Outside Readings and Links:}
\begin{enumerate}
    \item
    \item
    \item
    \item
\end{enumerate}

\section*{\solutionsname} \loadSolutions

\hr

\mydisclaim \myfooter

Last modified:  \flastmod

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% TeX-master: t
%%% End:
